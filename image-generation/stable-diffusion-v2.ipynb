{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "stable-diffusion.ipynb",
   "private_outputs": true,
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU",
  "gpuClass": "standard"
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import platform\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import int64\n",
    "from PIL.Image import Image\n",
    "from diffusers import EulerDiscreteScheduler\n",
    "from diffusers import StableDiffusionPipeline\n",
    "from verta import Client\n",
    "from verta.dataset import Path\n",
    "from verta.dataset.entities import Dataset\n",
    "from verta.dataset.entities import DatasetVersion\n",
    "from verta.deployment import DeployedModel\n",
    "from verta.registry import VertaModelBase, verify_io, task_type\n",
    "from verta.registry.entities import RegisteredModel, RegisteredModelVersion\n",
    "from verta.environment import Python\n",
    "from verta.registry import data_type\n",
    "from verta.endpoint import Endpoint\n",
    "from verta.utils import ModelAPI"
   ],
   "metadata": {
    "id": "oP_dBQpSCIkY"
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got VERTA_HOST from environment\n",
      "got VERTA_EMAIL from environment\n",
      "got VERTA_DEV_KEY from environment\n",
      "connection successfully established\n"
     ]
    }
   ],
   "source": [
    "os.environ['VERTA_EMAIL'] = 'cory@verta.ai'\n",
    "os.environ['VERTA_DEV_KEY'] = '154a34ad-2cd2-4d5d-b87c-2b809e075faa'\n",
    "os.environ['VERTA_HOST'] = 'cj.dev.verta.ai'\n",
    "client: Client = Client()\n",
    "project_name = \"Stable Diffusion v2 Example\"\n",
    "endpoint_name = \"Stable_Diffusion_v2\"\n",
    "dataset_name = \"Stable Diffusion v2 prebuilt pipeline\"\n",
    "default_image_width = 512\n",
    "default_image_height = 512\n",
    "default_guidance_scale = 9\n",
    "default_num_inference_steps = 25\n",
    "default_num_images = 1\n",
    "data_path = 'data/'\n",
    "pipeline_path = 'data/pipeline'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# create the local data directory to store the prebuilt assets\n",
    "os.makedirs(\n",
    "    os.path.dirname(data_path),\n",
    "    exist_ok=True,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "configuring scheduler\n",
      "configuring pipeline\n"
     ]
    },
    {
     "data": {
      "text/plain": "Fetching 12 files:   0%|          | 0/12 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0821562706e44a2585006c6f709bee9c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"configuring scheduler\")\n",
    "model_id = \"stabilityai/stable-diffusion-2-1\"\n",
    "scheduler: EulerDiscreteScheduler = EulerDiscreteScheduler.from_pretrained(model_id, subfolder=\"scheduler\")\n",
    "\n",
    "print(\"configuring pipeline\")\n",
    "revision = 'fp16'\n",
    "torch_dtype = torch.float16\n",
    "\n",
    "processor = platform.processor()\n",
    "# initialize the image pipeline using custom setting for M1/M2 mac\n",
    "if processor == 'arm':\n",
    "    # ARM-based Macs do not support the fp16 revision nor the float16 dtype when initializing the pipeline\n",
    "    pipe = StableDiffusionPipeline.from_pretrained(\n",
    "        model_id,\n",
    "        scheduler=scheduler\n",
    "    )\n",
    "else:\n",
    "    # x86 based OSes can use the fp16 revision and float16 dtype\n",
    "    pipe = StableDiffusionPipeline.from_pretrained(\n",
    "        model_id,\n",
    "        scheduler=scheduler,\n",
    "        torch_dtype=torch_dtype,\n",
    "        revision=revision,\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "storing pretrained pipeline to disk\n"
     ]
    }
   ],
   "source": [
    "# Store the pretrained model to disk\n",
    "print(\"storing pretrained pipeline to disk\")\n",
    "StableDiffusionPipeline.save_pretrained(pipe, save_directory=pipeline_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating a dataset for the pretrained pipeline\n",
      "got existing Dataset: Stable Diffusion v2 prebuilt pipeline\n"
     ]
    }
   ],
   "source": [
    "# create a dataset out of the pretrained model\n",
    "print(\"creating a dataset for the pretrained pipeline\")\n",
    "dataset: Dataset = client.get_or_create_dataset(name=dataset_name)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created new Dataset Version: 1 for Stable Diffusion v2 prebuilt pipeline\n",
      "uploading data/pipeline/model_index.json to ModelDB\n",
      "uploading part 1\r\n",
      "upload complete\n",
      "uploading data/pipeline/tokenizer/vocab.json to ModelDB\n",
      "uploading part 1\r\n",
      "upload complete\n",
      "uploading data/pipeline/tokenizer/special_tokens_map.json to ModelDB\n",
      "uploading part 1\r\n",
      "upload complete\n",
      "uploading data/pipeline/unet/diffusion_pytorch_model.bin to ModelDB\n",
      "uploading part 55\r\n",
      "upload complete\n",
      "uploading data/pipeline/vae/diffusion_pytorch_model.bin to ModelDB\n",
      "uploading part 6\r\n",
      "upload complete\n",
      "uploading data/pipeline/tokenizer/merges.txt to ModelDB\n",
      "uploading part 1\r\n",
      "upload complete\n",
      "uploading data/pipeline/text_encoder/config.json to ModelDB\n",
      "uploading part 1\r\n",
      "upload complete\n",
      "uploading data/pipeline/unet/config.json to ModelDB\n",
      "uploading part 1\r\n",
      "upload complete\n",
      "uploading data/pipeline/vae/config.json to ModelDB\n",
      "uploading part 1\r\n",
      "upload complete\n",
      "uploading data/pipeline/scheduler/scheduler_config.json to ModelDB\n",
      "uploading part 1\r\n",
      "upload complete\n",
      "uploading data/pipeline/tokenizer/tokenizer_config.json to ModelDB\n",
      "uploading part 1\r\n",
      "upload complete\n",
      "uploading data/pipeline/text_encoder/pytorch_model.bin to ModelDB\n",
      "uploading part 22\r\n",
      "upload complete\n"
     ]
    }
   ],
   "source": [
    "content: Path = Path([pipeline_path], enable_mdb_versioning=True)\n",
    "dataset_version: DatasetVersion = dataset.create_version(content)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "\n",
    "# define a custom verta model that will use prebuilt pipeline in the dataset to run the prediction\n",
    "class StableDiffusionV2Generator(VertaModelBase):\n",
    "    def __init__(self, artifacts):\n",
    "        local_dataset_version: DatasetVersion = client.get_dataset(name=dataset_name).get_latest_version()\n",
    "        local_path = '.'\n",
    "        print(\"initializing from dataset version {}, downloading content to path {}\".format(local_dataset_version.version, local_path))\n",
    "        local_dataset_version.get_content().download(download_to_path=local_path)\n",
    "        print(\"download complete, instantiating pipeline\")\n",
    "        pipeline: StableDiffusionPipeline = StableDiffusionPipeline.from_pretrained(pipeline_path)\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        print(\"configuring pipeline device {}\".format(device))\n",
    "        self.pipeline: StableDiffusionPipeline = pipeline.to(device)\n",
    "        print(\"pipeline ready for predictions\")\n",
    "\n",
    "    @verify_io\n",
    "    def predict(self, batch_input):\n",
    "        model_input = batch_input[0]\n",
    "        prompt = model_input[0]\n",
    "        height = model_input[1]\n",
    "        width = model_input[2]\n",
    "        guidance_scale = model_input[3]\n",
    "        num_inference_steps = model_input[4]\n",
    "        print(\"executing pipeline with prompt '{}', using guidance scale {}, {} inference steps, and dimensions {}x{}\".format(prompt, guidance_scale, num_inference_steps, width, height))\n",
    "        images = self.pipeline(\n",
    "            prompt,\n",
    "            num_images_per_prompt=default_num_images,\n",
    "            guidance_scale=guidance_scale,\n",
    "            num_inference_steps=num_inference_steps,\n",
    "            height=height,\n",
    "            width=width,\n",
    "        ).images\n",
    "        print(\"prediction complete for prompt '{}'\".format(prompt))\n",
    "        image: Image = images[0]\n",
    "        print(\"resulting image is {}\".format(image.info))\n",
    "        # convert the image to a byte array\n",
    "        image_bytes = io.BytesIO()\n",
    "        image.save(image_bytes, format=image.format)\n",
    "        return [image_bytes.getvalue(), image.height, image.width, guidance_scale, num_inference_steps]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "configuring verta model\n",
      "got existing RegisteredModel: Stable Diffusion v2 Example\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cory/.pyenv/versions/verta3.9.14/lib/python3.9/site-packages/verta/_internal_utils/_utils.py:1457: UserWarning: Registered Model with name Stable Diffusion v2 Example already exists; cannot set `desc`, `labels`, `public_within_org`, or `visibility`\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# create the registered model\n",
    "print(\"configuring verta model\")\n",
    "registered_model: RegisteredModel = client.get_or_create_registered_model(name=project_name, desc=\"Stable Diffusion v2 text-to-image generator\", data_type=data_type.Image(), task_type=task_type.Other())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# build the model api\n",
    "model_api: ModelAPI = ModelAPI(\n",
    "    pd.DataFrame.from_records(\n",
    "        [{\"prompt\": \"the prompt\",\n",
    "          \"image_height\": default_image_height,\n",
    "          \"image_width\": default_image_width,\n",
    "          \"guidance_scale\": default_guidance_scale,\n",
    "          \"num_inference_steps\": default_num_inference_steps}]),\n",
    "    pd.DataFrame.from_records([\n",
    "        {\"image_data\": \"data\",\n",
    "         \"image_height\": default_image_height,\n",
    "         \"image_width\": default_image_width,\n",
    "         \"guidance_scale\": default_guidance_scale,\n",
    "         \"num_inference_steps\": default_num_inference_steps}]),\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cory/.pyenv/versions/verta3.9.14/lib/python3.9/site-packages/verta/_internal_utils/_pip_requirements_utils.py:213: UserWarning: 'diffusers~=0.10.2' does not use '=='; for reproducibility in deployment, it will be replaced with an exact pin of the currently-installed version\n",
      "  warnings.warn(msg)\n",
      "/Users/cory/.pyenv/versions/verta3.9.14/lib/python3.9/site-packages/verta/_internal_utils/_pip_requirements_utils.py:213: UserWarning: 'torch~=1.13.0' does not use '=='; for reproducibility in deployment, it will be replaced with an exact pin of the currently-installed version\n",
      "  warnings.warn(msg)\n",
      "/Users/cory/.pyenv/versions/verta3.9.14/lib/python3.9/site-packages/verta/_internal_utils/_pip_requirements_utils.py:213: UserWarning: 'requests~=2.28.1' does not use '=='; for reproducibility in deployment, it will be replaced with an exact pin of the currently-installed version\n",
      "  warnings.warn(msg)\n",
      "/Users/cory/.pyenv/versions/verta3.9.14/lib/python3.9/site-packages/verta/_internal_utils/_pip_requirements_utils.py:213: UserWarning: 'scikit-learn~=1.2.0' does not use '=='; for reproducibility in deployment, it will be replaced with an exact pin of the currently-installed version\n",
      "  warnings.warn(msg)\n",
      "/Users/cory/.pyenv/versions/verta3.9.14/lib/python3.9/site-packages/verta/_internal_utils/_pip_requirements_utils.py:213: UserWarning: 'pandas~=1.5.2' does not use '=='; for reproducibility in deployment, it will be replaced with an exact pin of the currently-installed version\n",
      "  warnings.warn(msg)\n",
      "/Users/cory/.pyenv/versions/verta3.9.14/lib/python3.9/site-packages/verta/_internal_utils/_pip_requirements_utils.py:213: UserWarning: 'Pillow~=9.3.0' does not use '=='; for reproducibility in deployment, it will be replaced with an exact pin of the currently-installed version\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created new ModelVersion: v26\n",
      "uploading model to Registry\n",
      "uploading part 1\r\n",
      "upload complete\n",
      "uploading model_api.json to Registry\n",
      "uploading part 1\r\n",
      "upload complete\n",
      "uploading custom_modules to Registry\n",
      "uploading part 1\r\n",
      "upload complete\n"
     ]
    }
   ],
   "source": [
    "# create the model version\n",
    "version = \"v26\"\n",
    "model_version: RegisteredModelVersion = registered_model.create_standard_model(\n",
    "    name=version,\n",
    "    model_cls=StableDiffusionV2Generator,\n",
    "    model_api = model_api,\n",
    "    environment=Python(requirements=Python.read_pip_file(\"requirements.txt\"))\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got existing dataset version: 565d07046d4b4c8e3bedc7f8f27aec3b2accce7fc291405d43b55ceee4a1dabc\n"
     ]
    }
   ],
   "source": [
    "dataset_version = dataset.get_latest_version()\n",
    "# log the dataset version that contains the prebuilt pipeline\n",
    "model_version.log_dataset_version(key=dataset_name, dataset_version=dataset_version)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got existing Endpoint: Stable_Diffusion_v2\n",
      "updating endpoint to model version 28\n",
      "waiting for update...."
     ]
    }
   ],
   "source": [
    "endpoint: Endpoint = client.get_or_create_endpoint(endpoint_name)\n",
    "print(\"updating endpoint to model version {}\".format(model_version.id))\n",
    "endpoint.update(model_version, wait=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# generate an image from a text prompt\n",
    "deployed_model: DeployedModel = endpoint.get_deployed_model()\n",
    "print(deployed_model)\n",
    "\n",
    "prediction = deployed_model.predict([[\"An artistic logo for an AI company named Verta\",64,64,9,1]])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<DeployedModel at https://cj.dev.verta.ai/api/v1/predict/Stable_Diffusion_v2>\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "deployed model encountered an error: Traceback (most recent call last):\n  File \"/Users/cory/.pyenv/versions/verta3.9.14/lib/python3.9/site-packages/verta/registry/_verify_io.py\", line 76, in wrapper\n  File \"/var/folders/dt/cmrgxdqj1zs__xh2nj_gq7r40000gn/T/ipykernel_4388/278191097.py\", line 21, in predict\n  File \"/root/.pyenv/versions/3.9.12/lib/python3.9/site-packages/torch/autograd/grad_mode.py\", line 27, in decorate_context\n    return func(*args, **kwargs)\n  File \"/root/.pyenv/versions/3.9.12/lib/python3.9/site-packages/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py\", line 473, in __call__\n    self.check_inputs(prompt, height, width, callback_steps)\n  File \"/root/.pyenv/versions/3.9.12/lib/python3.9/site-packages/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py\", line 366, in check_inputs\n    raise ValueError(f\"`prompt` has to be of type `str` or `list` but is {type(prompt)}\")\nValueError: `prompt` has to be of type `str` or `list` but is <class 'dict'>\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[17], line 5\u001B[0m\n\u001B[1;32m      2\u001B[0m deployed_model: DeployedModel \u001B[38;5;241m=\u001B[39m endpoint\u001B[38;5;241m.\u001B[39mget_deployed_model()\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28mprint\u001B[39m(deployed_model)\n\u001B[0;32m----> 5\u001B[0m prediction \u001B[38;5;241m=\u001B[39m \u001B[43mdeployed_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43m{\u001B[49m\n\u001B[1;32m      6\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mprompt\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mAn artistic logo for an AI company named Verta\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      7\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mwidth\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m64\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      8\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mheight\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m64\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      9\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mguidance_scale\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m9\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     10\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mnum_inference_steps\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\n\u001B[1;32m     11\u001B[0m \u001B[43m}\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.pyenv/versions/verta3.9.14/lib/python3.9/site-packages/verta/deployment/_deployedmodel.py:253\u001B[0m, in \u001B[0;36mDeployedModel.predict\u001B[0;34m(self, x, compress, max_retries, always_retry_404, always_retry_429)\u001B[0m\n\u001B[1;32m    250\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:  \u001B[38;5;66;03m# from model back end; contains message (maybe)\u001B[39;00m\n\u001B[1;32m    251\u001B[0m         \u001B[38;5;66;03m# try to directly print message, otherwise line breaks appear as '\\n'\u001B[39;00m\n\u001B[1;32m    252\u001B[0m         msg \u001B[38;5;241m=\u001B[39m data\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmessage\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m json\u001B[38;5;241m.\u001B[39mdumps(data)\n\u001B[0;32m--> 253\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[1;32m    254\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdeployed model encountered an error: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(msg)\n\u001B[1;32m    255\u001B[0m         )\n\u001B[1;32m    256\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\n\u001B[1;32m    257\u001B[0m     response\u001B[38;5;241m.\u001B[39mstatus_code \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m500\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m response\u001B[38;5;241m.\u001B[39mstatus_code \u001B[38;5;129;01min\u001B[39;00m (\u001B[38;5;241m404\u001B[39m, \u001B[38;5;241m429\u001B[39m)\n\u001B[1;32m    258\u001B[0m ):  \u001B[38;5;66;03m# clientside error\u001B[39;00m\n\u001B[1;32m    259\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: deployed model encountered an error: Traceback (most recent call last):\n  File \"/Users/cory/.pyenv/versions/verta3.9.14/lib/python3.9/site-packages/verta/registry/_verify_io.py\", line 76, in wrapper\n  File \"/var/folders/dt/cmrgxdqj1zs__xh2nj_gq7r40000gn/T/ipykernel_4388/278191097.py\", line 21, in predict\n  File \"/root/.pyenv/versions/3.9.12/lib/python3.9/site-packages/torch/autograd/grad_mode.py\", line 27, in decorate_context\n    return func(*args, **kwargs)\n  File \"/root/.pyenv/versions/3.9.12/lib/python3.9/site-packages/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py\", line 473, in __call__\n    self.check_inputs(prompt, height, width, callback_steps)\n  File \"/root/.pyenv/versions/3.9.12/lib/python3.9/site-packages/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py\", line 366, in check_inputs\n    raise ValueError(f\"`prompt` has to be of type `str` or `list` but is {type(prompt)}\")\nValueError: `prompt` has to be of type `str` or `list` but is <class 'dict'>\n"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}
