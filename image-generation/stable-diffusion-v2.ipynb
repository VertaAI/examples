{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "stable-diffusion.ipynb",
   "private_outputs": true,
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU",
  "gpuClass": "standard"
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import platform\n",
    "import os\n",
    "import cloudpickle\n",
    "import torch\n",
    "import pandas as pd\n",
    "from diffusers import EulerDiscreteScheduler\n",
    "from diffusers import StableDiffusionPipeline\n",
    "from verta import Client\n",
    "from verta.dataset import Path\n",
    "from verta.dataset.entities import Dataset\n",
    "from verta.dataset.entities import DatasetVersion\n",
    "from verta.deployment import DeployedModel\n",
    "from verta.registry import VertaModelBase, verify_io, task_type\n",
    "from verta.registry.entities import RegisteredModel, RegisteredModelVersion\n",
    "from verta.environment import Python\n",
    "from verta.registry import data_type\n",
    "from verta.endpoint import Endpoint\n",
    "\n",
    "from verta.utils import ModelAPI"
   ],
   "metadata": {
    "id": "oP_dBQpSCIkY"
   },
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got VERTA_HOST from environment\n",
      "got VERTA_EMAIL from environment\n",
      "got VERTA_DEV_KEY from environment\n",
      "connection successfully established\n"
     ]
    }
   ],
   "source": [
    "os.environ['VERTA_EMAIL'] = 'cory@verta.ai'\n",
    "os.environ['VERTA_DEV_KEY'] = '154a34ad-2cd2-4d5d-b87c-2b809e075faa'\n",
    "os.environ['VERTA_HOST'] = 'cj.dev.verta.ai'\n",
    "client: Client = Client()\n",
    "project_name = \"Stable Diffusion v2 Example\"\n",
    "endpoint_name = \"Stable_Diffusion_v2\"\n",
    "dataset_name = \"Stable Diffusion v2 prebuilt pipeline\"\n",
    "version = \"v13\"\n",
    "default_image_width = 512\n",
    "default_image_height = 512\n",
    "default_guidance_scale = 9\n",
    "default_num_inference_steps = 25\n",
    "default_num_images = 1\n",
    "data_path = 'data/'\n",
    "pipeline_path = 'data/pipeline'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# create the local data directory to store the prebuilt assets\n",
    "os.makedirs(\n",
    "    os.path.dirname(data_path),\n",
    "    exist_ok=True,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "configuring scheduler\n",
      "configuring pipeline\n"
     ]
    },
    {
     "data": {
      "text/plain": "Fetching 12 files:   0%|          | 0/12 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cda8c1d97a53409c8489817468b81e54"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "configuring pipeline device\n"
     ]
    }
   ],
   "source": [
    "print(\"configuring scheduler\")\n",
    "model_id = \"stabilityai/stable-diffusion-2-1\"\n",
    "scheduler: EulerDiscreteScheduler = EulerDiscreteScheduler.from_pretrained(model_id, subfolder=\"scheduler\")\n",
    "\n",
    "print(\"configuring pipeline\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "revision = 'fp16'\n",
    "torch_dtype = torch.float16\n",
    "\n",
    "processor = platform.processor()\n",
    "# initialize the image pipeline using custom setting for M1/M2 mac\n",
    "if processor == 'arm':\n",
    "    # ARM-based Macs do not support the fp16 revision nor the float16 dtype when initializing the pipeline\n",
    "    pipe = StableDiffusionPipeline.from_pretrained(\n",
    "        model_id,\n",
    "        scheduler=scheduler\n",
    "    )\n",
    "else:\n",
    "    # x86 based OSes can use the fp16 revision and float16 dtype\n",
    "    pipe = StableDiffusionPipeline.from_pretrained(\n",
    "        model_id,\n",
    "        scheduler=scheduler,\n",
    "        torch_dtype=torch_dtype,\n",
    "        revision=revision,\n",
    "    )\n",
    "\n",
    "print(\"configuring pipeline device\")\n",
    "\n",
    "pipe: StableDiffusionPipeline = pipe.to(device)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "storing pretrained pipeline to disk\n"
     ]
    }
   ],
   "source": [
    "# Store the pretrained model to disk\n",
    "print(\"storing pretrained pipeline to disk\")\n",
    "StableDiffusionPipeline.save_pretrained(pipe, save_directory=pipeline_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating a dataset for the pretrained pipeline\n",
      "created new Dataset: Stable Diffusion v2 prebuilt pipeline in workspace: shared\n"
     ]
    }
   ],
   "source": [
    "# create a dataset out of the pretrained model\n",
    "print(\"creating a dataset for the pretrained pipeline\")\n",
    "dataset: Dataset = client.get_or_create_dataset(name=dataset_name)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created new Dataset Version: 1 for Stable Diffusion v2 prebuilt pipeline\n",
      "uploading data/pipeline/model_index.json to ModelDB\n",
      "uploading part 1\r\n",
      "upload complete\n",
      "uploading data/pipeline/tokenizer/vocab.json to ModelDB\n",
      "uploading part 1\r\n",
      "upload complete\n",
      "uploading data/pipeline/tokenizer/special_tokens_map.json to ModelDB\n",
      "uploading part 1\r\n",
      "upload complete\n",
      "uploading data/pipeline/unet/diffusion_pytorch_model.bin to ModelDB\n",
      "uploading part 55\r\n",
      "upload complete\n",
      "uploading data/pipeline/vae/diffusion_pytorch_model.bin to ModelDB\n",
      "uploading part 6\r\n",
      "upload complete\n",
      "uploading data/pipeline/tokenizer/merges.txt to ModelDB\n",
      "uploading part 1\r\n",
      "upload complete\n",
      "uploading data/pipeline/text_encoder/config.json to ModelDB\n",
      "uploading part 1\r\n",
      "upload complete\n",
      "uploading data/pipeline/unet/config.json to ModelDB\n",
      "uploading part 1\r\n",
      "upload complete\n",
      "uploading data/pipeline/vae/config.json to ModelDB\n",
      "uploading part 1\r\n",
      "upload complete\n",
      "uploading data/pipeline/scheduler/scheduler_config.json to ModelDB\n",
      "uploading part 1\r\n",
      "upload complete\n",
      "uploading data/pipeline/tokenizer/tokenizer_config.json to ModelDB\n",
      "uploading part 1\r\n",
      "upload complete\n",
      "uploading data/pipeline/text_encoder/pytorch_model.bin to ModelDB\n",
      "uploading part 22\r\n",
      "upload complete\n"
     ]
    }
   ],
   "source": [
    "content: Path = Path([pipeline_path], enable_mdb_versioning=True)\n",
    "dataset_version: DatasetVersion = dataset.create_version(content)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# define a custom verta model that will use prebuilt pipeline in the dataset to run the prediction\n",
    "class StableDiffusionV2Generator(VertaModelBase):\n",
    "    def __init__(self, artifacts):\n",
    "        local_dataset_version: DatasetVersion = client.get_dataset(name=dataset_name).get_latest_version()\n",
    "        local_dataset_version.get_content().download()\n",
    "        self.pipeline = StableDiffusionPipeline.from_pretrained(pipeline_path)\n",
    "\n",
    "    @verify_io\n",
    "    def predict(self, prompt):\n",
    "        # todo convert the parameters to inputs\n",
    "        images = self.pipeline(\n",
    "            prompt,\n",
    "            num_images_per_prompt=default_num_images,\n",
    "            guidance_scale=default_guidance_scale,\n",
    "            num_inference_steps=default_num_inference_steps,\n",
    "            height=default_image_height,\n",
    "            width=default_image_width,\n",
    "        ).images\n",
    "        return [images[0], default_image_height, default_image_width, default_guidance_scale, default_num_inference_steps]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "configuring verta model\n",
      "created new RegisteredModel: Stable Diffusion v2 Example in workspace: shared\n"
     ]
    }
   ],
   "source": [
    "# create the registered model\n",
    "print(\"configuring verta model\")\n",
    "registered_model: RegisteredModel = client.get_or_create_registered_model(name=project_name, data_type=data_type.Image(), task_type=task_type.Other())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# build the model api\n",
    "model_api: ModelAPI = ModelAPI(\n",
    "    pd.DataFrame.from_records(\n",
    "        [{\"prompt\": \"the prompt\"}]),\n",
    "    pd.DataFrame.from_records([{\"image_data\": \"\", \"image_height\": default_image_height, \"image_width\": default_image_width, \"guidance_scale\": default_guidance_scale, \"num_inference_steps\": default_num_inference_steps}]),\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created new ModelVersion: v13\n",
      "uploading model to Registry\n",
      "uploading part 1\r\n",
      "upload complete\n",
      "uploading model_api.json to Registry\n",
      "uploading part 1\r\n",
      "upload complete\n",
      "uploading custom_modules to Registry\n",
      "uploading part 1\r\n",
      "upload complete\n"
     ]
    }
   ],
   "source": [
    "# create the model version\n",
    "model_version: RegisteredModelVersion = registered_model.create_standard_model(\n",
    "    name=version,\n",
    "    model_cls=StableDiffusionV2Generator,\n",
    "    model_api = model_api,\n",
    "    environment=Python(requirements=Python.read_pip_file(\"requirements.txt\"))\n",
    ")\n",
    "\n",
    "# log the dataset version that contains the prebuilt pipeline\n",
    "model_version.log_dataset_version(key=dataset_name, dataset_version=dataset_version)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# model_version: RegisteredModelVersion = registered_model.get_or_create_version(name=version)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "waiting for update.........."
     ]
    }
   ],
   "source": [
    "endpoint: Endpoint = client.get_or_create_endpoint(endpoint_name)\n",
    "endpoint.update(model_version, wait=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# generate an image from a text prompt\n",
    "deployed_model: DeployedModel = endpoint.get_deployed_model()\n",
    "prediction = deployed_model.predict([\"An artistic logo for an AI company named Verta\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}
