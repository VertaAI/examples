{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tracking S3 dataset versions using Verta\n",
    "\n",
    "Verta's experiment management system enables data scientists to track dataset versions stored on S3.\n",
    "\n",
    "This notebook shows how to use Verta's experiment management system to track dataset versions. See Verta [documentation](https://verta.readthedocs.io/en/master/_autogen/verta.dataset.html) for full details on Verta's dataset versioning capabilities.\n",
    "\n",
    "Updated for Verta version: 0.18.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/VertaAI/examples/blob/main/experiment_management/dataset-versioning/s3-dataset-versioning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: you may need pip3 instead of pip\n",
    "!pip install boto3\n",
    "!pip install wget\n",
    "\n",
    "# from __future__ import print_function\n",
    "\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "from datetime import datetime\n",
    "import itertools\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn\n",
    "from sklearn import model_selection\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "\n",
    "import boto3\n",
    "import wget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1 Verta import and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restart your notebook if prompted on Colab\n",
    "try:\n",
    "    import verta\n",
    "except ImportError:\n",
    "    !pip install verta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ['VERTA_EMAIL'] = \n",
    "# os.environ['VERTA_DEV_KEY'] = \n",
    "# os.environ['VERTA_HOST']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from verta import Client\n",
    "from verta.utils import ModelAPI\n",
    "import os\n",
    "\n",
    "client = Client(os.environ['VERTA_HOST'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from verta.dataset import S3\n",
    "\n",
    "# create a dataset\n",
    "dataset = client.set_dataset(name=\"Census Income S3\")\n",
    "\n",
    "# create a version using the S3 versioning convenience function\n",
    "# https://verta.readthedocs.io/en/master/_autogen/verta.dataset.S3.html#verta.dataset.S3\n",
    "dataset_version = dataset.create_version(S3(\"s3://verta-starter\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset, dataset_version)\n",
    "# Notice that the S3 convenience function has collected metadata about \n",
    "# every blob in the S3 bucket including its checksum, and last modified \n",
    "# dates. Verta will use this info to determine if a new version muts be \n",
    "# created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = \"./\"\n",
    "train_data_filename = DATASET_PATH + \"census-train.csv\"\n",
    "test_data_filename = DATASET_PATH + \"census-test.csv\"\n",
    "\n",
    "def download_starter_dataset(bucket_name):\n",
    "    if not os.path.exists(DATASET_PATH + \"census-train.csv\"):\n",
    "        train_data_url = \"http://s3.amazonaws.com/\" + bucket_name + \"/census-train.csv\"\n",
    "        if not os.path.isfile(train_data_filename):\n",
    "            wget.download(train_data_url)\n",
    "\n",
    "    if not os.path.exists(DATASET_PATH + \"census-test.csv\"):\n",
    "        test_data_url = \"http://s3.amazonaws.com/\" + bucket_name + \"/census-test.csv\"\n",
    "        if not os.path.isfile(test_data_filename):\n",
    "            wget.download(test_data_url)\n",
    "\n",
    "download_starter_dataset(\"verta-starter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"./census-train.csv\")\n",
    "X_train = df_train.iloc[:,:-1]\n",
    "Y_train = df_train.iloc[:, -1]\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Train a Model and associate the dataset version with it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create object to track experiment run\n",
    "run = client.set_experiment_run()\n",
    "\n",
    "# log training data\n",
    "run.log_dataset_version(\"train\", dataset_version)\n",
    "\n",
    "# ---------------------- other tracking below ------------------------\n",
    "\n",
    "# create validation split\n",
    "(X_val_train, X_val_test,\n",
    " Y_val_train, Y_val_test) = model_selection.train_test_split(X_train, Y_train,\n",
    "                                                             test_size=0.2,\n",
    "                                                             shuffle=True)\n",
    "# log hyperparameters\n",
    "hyperparams = {\"C\" : 10}\n",
    "run.log_hyperparameters(hyperparams)\n",
    "print(hyperparams, end=' ')\n",
    "\n",
    "# create and train model\n",
    "model = linear_model.LogisticRegression(**hyperparams)\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "# calculate and log validation accuracy\n",
    "val_acc = model.score(X_val_test, Y_val_test)\n",
    "run.log_metric(\"val_acc\", val_acc)\n",
    "print(\"Validation accuracy: {:.4f}\".format(val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch the dataset version info\n",
    "run.get_dataset_version(\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
