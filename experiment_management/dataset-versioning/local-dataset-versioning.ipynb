{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tracking local dataset versions using Verta\n",
    "\n",
    "Verta's experiment management system enables data scientists to track dataset versions stored locally.\n",
    "\n",
    "This notebook shows how to use Verta's experiment management system to track dataset versions. See Verta [documentation](https://verta.readthedocs.io/en/master/_autogen/verta.dataset.html) for full details on Verta's dataset versioning capabilities.\n",
    "\n",
    "Updated for Verta version: 0.18.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/VertaAI/modeldb/blob/master/client/workflows/demos/census-end-to-end-local-data-example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: you may need pip3 instead of pip\n",
    "!pip install wget\n",
    "\n",
    "# from __future__ import print_function\n",
    "\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "from datetime import datetime\n",
    "import itertools\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn\n",
    "from sklearn import model_selection\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "\n",
    "import wget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1 Verta import and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restart your notebook if prompted on Colab\n",
    "try:\n",
    "    import verta\n",
    "except ImportError:\n",
    "    !pip install verta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ['VERTA_EMAIL'] = \n",
    "# os.environ['VERTA_DEV_KEY'] = \n",
    "# os.environ['VERTA_HOST']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from verta import Client\n",
    "from verta.utils import ModelAPI\n",
    "import os\n",
    "\n",
    "client = Client(os.environ['VERTA_HOST'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import wget\n",
    "except ImportError:\n",
    "    !pip install wget  # you may need pip3\n",
    "    import wget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from verta.dataset import Path\n",
    "\n",
    "dataset = client.set_dataset(name=\"Census Income Local\")\n",
    "\n",
    "# Assume census-train.csv and census-test.csv exist locally, otherwise use the following code\n",
    "# DATASET_PATH = \"./\"\n",
    "# train_data_filename = DATASET_PATH + \"census-train.csv\"\n",
    "# test_data_filename = DATASET_PATH + \"census-test.csv\"\n",
    "\n",
    "# def download_starter_dataset(bucket_name):\n",
    "#     if not os.path.exists(DATASET_PATH + \"census-train.csv\"):\n",
    "#         train_data_url = \"http://s3.amazonaws.com/\" + bucket_name + \"/census-train.csv\"\n",
    "#         if not os.path.isfile(train_data_filename):\n",
    "#             wget.download(train_data_url)\n",
    "\n",
    "#     if not os.path.exists(DATASET_PATH + \"census-test.csv\"):\n",
    "#         test_data_url = \"http://s3.amazonaws.com/\" + bucket_name + \"/census-test.csv\"\n",
    "#         if not os.path.isfile(test_data_filename):\n",
    "#             wget.download(test_data_url)\n",
    "\n",
    "# download_starter_dataset(\"verta-starter\")\n",
    "\n",
    "\n",
    "# create a version using the Path versioning convenience function\n",
    "# https://verta.readthedocs.io/en/master/_autogen/verta.dataset.Path.html#verta.dataset.Path\n",
    "dataset_version = dataset.create_version(Path(\"census-train.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset, dataset_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = \"./\"\n",
    "\n",
    "train_data_filename = DATASET_PATH + \"census-train.csv\"\n",
    "test_data_filename = DATASET_PATH + \"census-test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(train_data_filename)\n",
    "X_train = df_train.iloc[:,:-1]\n",
    "Y_train = df_train.iloc[:, -1]\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Train a Model and associate the dataset version with it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create object to track experiment run\n",
    "run = client.set_experiment_run()\n",
    "\n",
    "# log training data\n",
    "run.log_dataset_version(\"train\", dataset_version)\n",
    "\n",
    "# ---------------------- other tracking below ------------------------\n",
    "\n",
    "# create validation split\n",
    "(X_val_train, X_val_test,\n",
    " Y_val_train, Y_val_test) = model_selection.train_test_split(X_train, Y_train,\n",
    "                                                             test_size=0.2,\n",
    "                                                             shuffle=True)\n",
    "# log hyperparameters\n",
    "hyperparams = {\"C\" : 10}\n",
    "run.log_hyperparameters(hyperparams)\n",
    "print(hyperparams, end=' ')\n",
    "\n",
    "# create and train model\n",
    "model = linear_model.LogisticRegression(**hyperparams)\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "# calculate and log validation accuracy\n",
    "val_acc = model.score(X_val_test, Y_val_test)\n",
    "run.log_metric(\"val_acc\", val_acc)\n",
    "print(\"Validation accuracy: {:.4f}\".format(val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch the dataset version info\n",
    "run.get_dataset_version(\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
