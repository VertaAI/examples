{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Verta Manged Dataset versioning on S3\n",
    "\n",
    "Verta experiment management provides functionality to fully manage dataset versions with Verta (i.e., store data in Verta artifact store and provide full data reproducibility)\n",
    "\n",
    "This notebook shows how to use Verta's experiment management system to use Verta managed dataset versions. See Verta [documentation](https://verta.readthedocs.io/en/master/_autogen/verta.dataset.html) for full details on Verta's dataset versioning capabilities.\n",
    "\n",
    "Updated for Verta version: 0.18.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/VertaAI/examples/blob/main/experiment_management/dataset-versioning/verta-managed-dataset-versioning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "import itertools\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn\n",
    "from sklearn import model_selection\n",
    "from sklearn import linear_model\n",
    "import wget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1 Verta import and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restart your notebook if prompted on Colab\n",
    "try:\n",
    "    import verta\n",
    "except ImportError:\n",
    "    !pip install verta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ['VERTA_EMAIL'] = \n",
    "# os.environ['VERTA_DEV_KEY'] = \n",
    "# os.environ['VERTA_HOST']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from verta import Client\n",
    "from verta.utils import ModelAPI\n",
    "import os\n",
    "\n",
    "client = Client(os.environ['VERTA_HOST'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = \"verta-starter\"\n",
    "key = \"census-train.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we download our data from S3 for use in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.curdir\n",
    "train_data_filename = os.path.join(data_dir, key)\n",
    "\n",
    "if not os.path.exists(train_data_filename):\n",
    "    train_data_url = \"http://s3.amazonaws.com/{}/{}\".format(bucket, key)\n",
    "    wget.download(train_data_url, train_data_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we version our dataset; with `enable_mdb_versioning=True`, the client will obtain the data file(s) from S3 and store them in ModelDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from verta.dataset import S3\n",
    "\n",
    "dataset = client.set_dataset(name=\"Census Income S3\")\n",
    "content = S3(\"s3://{}/{}\".format(bucket, key), enable_mdb_versioning=True)\n",
    "dataset_version = dataset.create_version(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(train_data_filename)\n",
    "X_train = df_train.iloc[:,:-1]\n",
    "y_train = df_train.iloc[:, -1]\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create object to track experiment run\n",
    "proj = client.set_project(\"Verta Managed Dataset Versioning\")\n",
    "expt = client.set_experiment(\"My Experiment\")\n",
    "run = client.set_experiment_run()\n",
    "\n",
    "# log training data\n",
    "run.log_dataset_version(\"train\", dataset_version)\n",
    "\n",
    "# ---------------------- other tracking below ------------------------\n",
    "\n",
    "# create validation split\n",
    "(X_val_train, X_val_test,\n",
    " y_val_train, y_val_test) = model_selection.train_test_split(X_train, y_train,\n",
    "                                                             test_size=0.2,\n",
    "                                                             shuffle=True)\n",
    "# log hyperparameters\n",
    "hyperparams = {\"C\" : 10}\n",
    "run.log_hyperparameters(hyperparams)\n",
    "print(hyperparams, end=' ')\n",
    "\n",
    "# create and train model\n",
    "model = linear_model.LogisticRegression(**hyperparams)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# calculate and log validation accuracy\n",
    "val_acc = model.score(X_val_test, y_val_test)\n",
    "run.log_metric(\"val_acc\", val_acc)\n",
    "print(\"Validation accuracy: {:.4f}\".format(val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch the dataset version info\n",
    "run.get_dataset_version(\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say our data file becomes lost in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.remove(train_data_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we've used Verta to manage our data, we can obtain the dataset version from our experiment run, and use it to recover our original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "run = proj.expt_runs[0]\n",
    "version = run.get_dataset_version(\"train\")\n",
    "\n",
    "version.get_content().download(\n",
    "    \"s3://{}/{}\".format(bucket, key),\n",
    "    download_to_path=train_data_filename,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(train_data_filename).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
