{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from verta._internal_utils._utils import proto_to_json\n",
    "from verta.monitoring.profiler import ContinuousHistogramProfiler, BinaryHistogramProfiler\n",
    "from verta.data_types import _VertaDataType\n",
    "from verta.monitoring import profiler\n",
    "\n",
    "from verta._protos.public.monitoring.Summary_pb2 import CreateSummarySample\n",
    "from verta._protos.public.monitoring.DeploymentIntegration_pb2 import FeatureDataInModelVersion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import verta\n",
    "from datetime import datetime, timedelta, timezone\n",
    "\n",
    "from verta.data_types import (\n",
    "    DiscreteHistogram,\n",
    "    FloatHistogram,\n",
    "    NumericValue,\n",
    ")\n",
    "\n",
    "from verta.monitoring.profiler import (\n",
    "    MissingValuesProfiler,\n",
    "    BinaryHistogramProfiler,\n",
    "    ContinuousHistogramProfiler,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Notes:\n",
    "- Requirement will be that the thing passed to profile is the same thing that predict will take in\n",
    "- Aside: Missing values could be encoded as numeric\n",
    "- Histogram classes are not json serializable, so unclear what \"contents\" should be\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/mvartak/Downloads/census-train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_time_attrs_to_feature_data(feature_data):\n",
    "    time_millis = int(time.time() * 1000)\n",
    "    feature_data.created_at_millis = time_millis\n",
    "    feature_data.time_window_start_at_millis = time_millis\n",
    "    feature_data.time_window_end_at_millis = time_millis\n",
    "    \n",
    "def add_labels_to_feature_data(feature_data, labels):\n",
    "    for key in labels.keys():\n",
    "        feature_data.labels[key] = labels[key]\n",
    "\n",
    "def create_missing_value_summary(df, col, labels):\n",
    "    feature_data = FeatureDataInModelVersion()\n",
    "    feature_data.feature_name = col\n",
    "    feature_data.profiler_name = \"ContinuousHistogramProfiler\"\n",
    "    feature_data.summary_name = col + \"--\" + \"MissingValues\"\n",
    "    feature_data.summary_type_name = \"DiscreteHistogram\"    \n",
    "    sample = MissingValuesProfiler(columns=[col]).profile(df)\n",
    "    for _, histogram in sample.items(): \n",
    "        feature_data.content = json.dumps(DiscreteHistogram(\n",
    "            buckets = histogram._buckets,\n",
    "            data = histogram._data,\n",
    "        )._as_dict())\n",
    "        break\n",
    "    add_time_attrs_to_feature_data(feature_data)\n",
    "    add_labels_to_feature_data(feature_data, labels)\n",
    "    return feature_data\n",
    "\n",
    "def create_continuous_histogram_summary(df, col, labels):\n",
    "    feature_data = FeatureDataInModelVersion()\n",
    "    feature_data.feature_name = col\n",
    "    feature_data.profiler_name = \"ContinuousHistogramProfiler\"\n",
    "    feature_data.summary_name = col + \"--\" + \"Distribution\"\n",
    "    feature_data.summary_type_name = \"FloatHistogram\"    \n",
    "    sample = ContinuousHistogramProfiler(columns=[col]).profile(df)\n",
    "    for _, histogram in sample.items(): \n",
    "        feature_data.content = json.dumps(FloatHistogram(\n",
    "            bucket_limits = histogram._bucket_limits,\n",
    "            data = histogram._data,\n",
    "        )._as_dict())\n",
    "        feature_data.profiler_parameters = json.dumps({\"bins\" : histogram._bucket_limits})\n",
    "        break\n",
    "    add_time_attrs_to_feature_data(feature_data)\n",
    "    add_labels_to_feature_data(feature_data, labels)\n",
    "    return feature_data\n",
    "\n",
    "def create_discrete_histogram_summary(df, col, labels):\n",
    "    feature_data = FeatureDataInModelVersion()\n",
    "    feature_data.feature_name = col\n",
    "    feature_data.profiler_name = \"BinaryHistogramProfiler\"\n",
    "    feature_data.summary_name = col + \"--\" + \"Distribution\"\n",
    "    feature_data.summary_type_name = \"DiscreteHistogram\"    \n",
    "    sample = BinaryHistogramProfiler(columns=[col]).profile(df)\n",
    "    for _, histogram in sample.items(): \n",
    "        feature_data.content = json.dumps(DiscreteHistogram(\n",
    "            buckets = histogram._buckets,\n",
    "            data = histogram._data,\n",
    "        )._as_dict())\n",
    "        feature_data.profiler_parameters = json.dumps({\"bins\" : histogram._buckets})\n",
    "        break\n",
    "    add_time_attrs_to_feature_data(feature_data)\n",
    "    add_labels_to_feature_data(feature_data, labels)\n",
    "    return feature_data\n",
    "\n",
    "def get_metadata_for_df(df):\n",
    "    metadata = {}\n",
    "    for column in df:\n",
    "        metadata[column] = {}\n",
    "        metadata[column][\"num_unique\"] = df[column].value_counts().size\n",
    "        metadata[column][\"type\"] = str(df[column].dtypes)\n",
    "    return metadata\n",
    "\n",
    "def profile_training_data(in_df, out_df):\n",
    "    # get metadata; currently getting extra info than necessary. May change later\n",
    "    in_df_metadata = get_metadata_for_df(in_df)\n",
    "    out_df_metadata = get_metadata_for_df(out_df)\n",
    "    \n",
    "    feature_data_list = []\n",
    "    \n",
    "    labels_list = [{\"col_type\" : \"input\"}, {\"col_type\" : \"output\"}]\n",
    "    metadata_list = [in_df_metadata, out_df_metadata]\n",
    "    \n",
    "    # we assume no overlap in names of input and output cols\n",
    "    for labels, metadata in zip(labels_list, metadata_list):\n",
    "        for key in metadata.keys():\n",
    "            # ignore unsupported types. currently only numeric\n",
    "            if metadata[key][\"type\"] not in [\"float64\", \"int64\"]:\n",
    "                continue\n",
    "                \n",
    "            feature_data_list.append(create_missing_value_summary(df, key, labels))\n",
    "            if metadata[key][\"num_unique\"] > 20:\n",
    "                feature_data_list.append(create_continuous_histogram_summary(df, key, labels))\n",
    "            else:\n",
    "                feature_data_list.append(create_discrete_histogram_summary(df, key, labels))\n",
    "    return feature_data_list\n",
    "\n",
    "def log_feature_data_and_vis_attributes(feature_data_list, rmv, er):\n",
    "    for idx in range(len(feature_data_list)):\n",
    "        rmv.add_attribute(\n",
    "            \"__verta_feature_data_\" + str(idx),\n",
    "            _utils.proto_to_json(feature_data_list[idx], False))\n",
    "        rmv.add_attribute(\n",
    "            (\"__verta_tdp_\" + feature_data_list[idx].summary_name)[:50], \n",
    "            json.loads(feature_data_list[idx].content))\n",
    "#         er.log_attribute(\n",
    "#             feature_data_list[idx].summary_name, \n",
    "#             json.loads(feature_data_list[idx].content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = profile_training_data(df.loc[:, df.columns != '>50k'], pd.DataFrame(df[\">50k\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_feature_data_and_vis_attributes(profile, registered_model_version, run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from verta.registry.entities import RegisteredModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = verta.Client(\"demo.dev.verta.ai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "registered_model = client.create_registered_model(\"test_model3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "registered_model_version = registered_model.create_version(\"dummy model8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "registered_model_version.add_attributes({\"__verta_feature_data_0\" : _utils.proto_to_json(profile[0], False)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile[0].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj = client.get_or_create_project(\"monitoring_testing\")\n",
    "expt = client.get_or_create_experiment(\"test\")\n",
    "run = client.create_experiment_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.log_attributes({\"__verta_feature_data_1\" : profile[0].content})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.log_attribute(\"test2\", DiscreteHistogram(**json.loads(profile[0][\"content\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_training_data_profile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from verta._internal_utils import _utils\n",
    "_utils.proto_to_json(profile[0], False),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_data_to_attribute_for_vis(profile[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.log_attribute(\"test6\", json.loads(profile[1].content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ers = proj.expt_runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ers[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import uuid\n",
    "\n",
    "\n",
    "cont_col = np.random.random(100)\n",
    "discrete_col = np.random.choice(5, 100)\n",
    "strs = ['a', 'b', 'c', 'd', 'e']\n",
    "string_discrete_col =  [strs[x] for x in np.random.choice(5, 100)]\n",
    "string_free_form =  [uuid.uuid4().hex.upper()[0:10] for x in range(100)]\n",
    "unsupported_col = [datetime.now() for x in range(100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.choice(5, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(list(zip(*[cont_col, discrete_col, string_discrete_col, string_free_form, unsupported_col])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget, os\n",
    "train_data_url = \"http://s3.amazonaws.com/verta-starter/spam.csv\"\n",
    "train_data_filename = wget.detect_filename(train_data_url)\n",
    "if not os.path.isfile(train_data_filename):\n",
    "    wget.download(train_data_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv(train_data_filename, delimiter=',', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "[str.isalnum(x) for x in \">50k\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\".join([x for x in name if str.isalnum(x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \">50_k\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\".join([x for x in name if (str.isalnum(x) or x == '_')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "            list(zip(cont_col, discrete_col, string_discrete_col, string_free_form, unsupported_col))\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(zip(lst, lst2)),\n",
    "               columns =['Name', 'val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_col = np.random.random(100)\n",
    "discrete_col = np.random.choice(5, 100)\n",
    "strs = ['a', 'b', 'c', 'd', 'e']\n",
    "string_discrete_col =  [strs[x] for x in np.random.choice(5, 100)]\n",
    "string_freeform_col =  [uuid.uuid4().hex.upper()[0:10] for x in range(100)]\n",
    "other_col = [datetime.now() for x in range(100)]\n",
    "output_col = np.random.choice(2, 100)\n",
    "\n",
    "col_names = ['Continuous_Numeric', 'Discrete_Numeric', 'Discrete_String', \"Freeform_String\",\n",
    "        \"Other\", \"Output_Col\"]\n",
    "supported_col_names = ['Continuous_Numeric', 'Discrete_Numeric', \"Output_Col\"]\n",
    "\n",
    "# create dataframes\n",
    "df  = pd.DataFrame(\n",
    "    list(zip(cont_col, discrete_col, string_discrete_col, string_freeform_col, \n",
    "        other_col, output_col)),\n",
    "    columns = col_names\n",
    ")\n",
    "print(df.columns)\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, df.columns != \"Output_Col\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, df.columns != \"Output_Col\"], pd.DataFrame(df[\"Output_Col\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.loads(profile[0].content)[\"discreteHistogram\"][\"buckets\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
