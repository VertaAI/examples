{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Registering PyTorch models on Verta\n",
    "\n",
    "Within Verta, a \"Model\" can be any arbitrary function: a traditional ML model (e.g., sklearn, PyTorch, TF, etc); a function (e.g., squaring a number, making a DB function etc.); or a mixture of the above (e.g., pre-processing code, a DB call, and then a model application.) See more [here](https://docs.verta.ai/verta/registry/concepts).\n",
    "\n",
    "This notebook provides an example of how to deploy a PyTorch model on Verta as a Verta Standard Model either via convenience functions or by extending [VertaModelBase](https://verta.readthedocs.io/en/master/_autogen/verta.registry.VertaModelBase.html?highlight=VertaModelBase#verta.registry.VertaModelBase)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook walks through initializing EfficientNet Classification model through torchvision models, and cataloging them to the Verta platform."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/VertaAI/examples/blob/registry_examples/registry/pytorch/pytorch-imagenet-model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install verta\n",
    "!python -m pip install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.io import read_image\n",
    "from torchvision.models import efficientnet_v2_m, EfficientNet_V2_M_Weights"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Register model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Define Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A model has to exist before we can register, so we will instantiate one here in our notebook."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Info**\n",
    "\n",
    "EfficientNetV2 are a family of image classification models, which achieve better parameter efficiency and faster training speed than prior arts. Built upon EfficientNetV1, EfficientNetV2 models use neural architecture search (NAS) to jointly optimize model size and training speed, and are scaled up in a way for faster training and inference speed.\n",
    "\n",
    "Reference Paper: [EfficientNetV2: Smaller Models and Faster Training](https://arxiv.org/abs/2104.00298) Git Repo: [EfficientNetV2 Pytorch Repo](https://github.com/pytorch/vision/tree/main/references/classification#efficientnet-v2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Initialize model with the best available weights\n",
    "weights = EfficientNet_V2_M_Weights.DEFAULT\n",
    "model = efficientnet_v2_m(weights=weights)\n",
    "model.eval()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a sanity check, we can validate that our model can produce predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load Image\n",
    "img_path = \"n02106662_German_shepherd.JPEG\" # https://raw.githubusercontent.com/EliSchwartz/imagenet-sample-images/master/n02106662_German_shepherd.JPEG\n",
    "img = read_image(img_path)\n",
    "\n",
    "# Step 2: Preprocess the image\n",
    "preprocess = weights.transforms()\n",
    "batch = preprocess(img).unsqueeze(0)\n",
    "\n",
    "# Step 3: Use the model and print the predicted category\n",
    "prediction = model(batch).squeeze(0).softmax(0)\n",
    "class_id = prediction.argmax().item()\n",
    "score = prediction[class_id].item()\n",
    "category_name = weights.meta[\"categories\"][class_id]\n",
    "print(f\"Predicted class: {category_name}: {100 * score:.1f}%\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Register Model to Verta Model Catalog"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the model is in a good shape, we can register it into the Verta platform.\n",
    "\n",
    "We'll connect to Verta through the [Verta Python Client](https://verta.readthedocs.io/en/main/_autogen/verta.Client.html)\n",
    "create a [registered model](https://verta.readthedocs.io/en/master/_autogen/verta.registry.entities.RegisteredModel.html) for our EfficientNet ImageNet Classification Model  \n",
    "and a [version](https://verta.readthedocs.io/en/master/_autogen/verta.registry.entities.RegisteredModelVersion.html) to associate this particular model with.\n",
    "\n",
    "All of these can be viewed in the Verta web app once they are created.\n",
    "\n",
    "Note: If your model uses CustomObject you have to register the model into the catalog using a serialized version of the model using the VertaModelBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paste your credentials in this cell or anywhere above this along with the code snippet to connect to Verta Platform\n",
    "\n",
    "from verta import Client\n",
    "\n",
    "client = Client(\n",
    "        #   host=\"app.verta.ai\",\n",
    "        #   email=\"user@verta.ai\",\n",
    "        #   dev_key=\"a765b2de-786d-466c-b2d8-thiye06f80d5\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create/Get a Verta registered model\n",
    "\n",
    "registered_model = client.get_or_create_registered_model(\n",
    "    \"EfficientNet\",\n",
    "    desc=\"Family of EfficientNet models for ImageNet Classification - 1000 Classes\",\n",
    "    labels=[\"CV\", \"Classification\", \"Neural Net\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from verta.environment import Python\n",
    "\n",
    "# uncommment the below if you want to load it from a saved model (h5 or tf saved)\n",
    "# import tf\n",
    "# model = tf.keras.models.load_model(\"<file_to_model.h5> or <path_to_tf_saved_model>\")\n",
    "\n",
    "model_version_v1 = registered_model.create_standard_model_from_torch(\n",
    "    model, # The loaded model object, can be the one trained in the same file or loaded from keras load_model function\n",
    "    environment=Python(requirements=[ # Add the required libraries for the model to run\n",
    "    \"torch\",\n",
    "    \"torchvision\",\n",
    "    ]), \n",
    "    name=\"V2M-torch\", # Name to identify the version in the model versions tab\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And That's it. You should now be able to see your Model, on your Catalog."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
