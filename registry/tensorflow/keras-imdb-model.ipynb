{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Registering a TF/Keras (IMBD Movie Review Classification) model on Verta\n",
    "\n",
    "Within Verta, a \"Model\" can be any arbitrary function: a traditional ML model (e.g., sklearn, PyTorch, TF, etc); a function (e.g., squaring a number, making a DB function etc.); or a mixture of the above (e.g., pre-processing code, a DB call, and then a model application.) See more [here](https://docs.verta.ai/verta/registry/concepts).\n",
    "\n",
    "This notebook provides an example of how to catalog a Keras model on Verta as a Verta Standard Model by convinience functions.\n",
    "\n",
    "Updated for Verta version: 0.21.0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook walks through training an RNN classification model through keras, and cataloging them to the Verta platform."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/VertaAI/examples/blob/registry_examples/registry/tensorflow/keras-imdb-model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install verta\n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Register Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 (Optional) Model Training \n",
    "\n",
    "A model has to exist before we can register, so we will also train one here in our notebook.\n",
    "\n",
    "If you already have a keras model saved in a file, you can skip this step and directly register it on the catalog"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.1 Load Training Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The IMDB large movie review dataset is a *binary classification* dataset—all the reviews have either a *positive* or *negative* sentiment.\n",
    "\n",
    "Download the dataset using [TFDS](https://www.tensorflow.org/datasets). The dataset comes with an inbuilt subword tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the dataset\n",
    "\n",
    "dataset, info = tfds.load('imdb_reviews/subwords8k', with_info=True,\n",
    "                          as_supervised=True)\n",
    "train_dataset, test_dataset = dataset['train'], dataset['test']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.2 Train/Test code"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Info**\n",
    "\n",
    "Build a `tf.keras.Sequential` model and start with an embedding layer. An embedding layer stores one vector per word. When called, it converts the sequences of word indices to sequences of vectors. These vectors are trainable. After training (on enough data), words with similar meanings often have similar vectors.\n",
    "\n",
    "A recurrent neural network (RNN) processes sequence input by iterating through the elements. RNNs pass the outputs from one timestep to their input—and then to the next.\n",
    "\n",
    "The `tf.keras.layers.Bidirectional` wrapper can also be used with an RNN layer. This propagates the input forward and backwards through the RNN layer and then concatenates the output. This helps the RNN to learn long range dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters\n",
    "\n",
    "BUFFER_SIZE = 10000\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE)\n",
    "train_dataset = train_dataset.padded_batch(BATCH_SIZE, train_dataset.output_shapes)\n",
    "\n",
    "test_dataset = test_dataset.padded_batch(BATCH_SIZE, test_dataset.output_shapes)\n",
    "\n",
    "tokenizer = info.features['text'].encoder\n",
    "\n",
    "hyperparams = {\n",
    "    'num_epochs': 5,\n",
    "    'optimizer': 'adam',\n",
    "    'loss': 'binary_crossentropy',\n",
    "    'vocab_size': tokenizer.vocab_size,\n",
    "    'metrics': 'accuracy'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(tokenizer.vocab_size, 64),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(loss=hyperparams['loss'],\n",
    "              optimizer=hyperparams['optimizer'],\n",
    "              metrics=[hyperparams['metrics']])\n",
    "\n",
    "history = model.fit(train_dataset,\n",
    "                    epochs=hyperparams['num_epochs'],\n",
    "                    validation_data=test_dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a sanity check, we can validate that our model can produce predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_dataset, verbose=0)\n",
    "\n",
    "print('Test Loss: {}'.format(test_loss))\n",
    "print('Test Accuracy: {}'.format(test_acc))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Register Model to Verta Model Catalog"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the model is in a good shape, we can register it into the Verta platform.\n",
    "\n",
    "We'll connect to Verta through the [Verta Python Client](https://verta.readthedocs.io/en/main/_autogen/verta.Client.html)\n",
    "create a [registered model](https://verta.readthedocs.io/en/master/_autogen/verta.registry.entities.RegisteredModel.html) for our Binary Text Classification Model  \n",
    "and a [version](https://verta.readthedocs.io/en/master/_autogen/verta.registry.entities.RegisteredModelVersion.html) to associate this particular model with.\n",
    "\n",
    "All of these can be viewed in the Verta web app once they are created.\n",
    "\n",
    "Note: If your model uses CustomObject you have to register the model into the catalog using a serialized version of the model by extending the [VertaModelBase](https://verta.readthedocs.io/en/master/_autogen/verta.registry.VertaModelBase.html?highlight=VertaModelBase#verta.registry.VertaModelBase) class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paste your credentials in this cell or anywhere above this along with the code snippet to connect to Verta Platform\n",
    "\n",
    "from verta import Client\n",
    "\n",
    "client = Client(\n",
    "        #   host=\"app.verta.ai\",\n",
    "        #   email=\"user@verta.ai\",\n",
    "        #   dev_key=\"a765b2de-786d-466c-b2d8-thiye06f80d5\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create/Get a Verta registered model\n",
    "\n",
    "registered_model = client.get_or_create_registered_model(\n",
    "    \"IMDB-Review-clf\",\n",
    "    desc=\"Binary text classifier to classify movie reviews as positive or negative\",\n",
    "    labels=[\"NLP\", \"Classification\", \"Neural Net\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from verta.environment import Python\n",
    "\n",
    "# uncommment the below if you want to load it from a saved model (h5 or tf saved)\n",
    "# import tf\n",
    "# model = tf.keras.models.load_model(\"<file_to_model.h5> or <path_to_tf_saved_model>\")\n",
    "\n",
    "model_version_v1 = registered_model.create_standard_model_from_keras(\n",
    "    model, # The loaded model object, can be the one trained in the same file or loaded from keras load_model function\n",
    "    environment=Python(requirements=[ # Add the required libraries for the model to run\n",
    "    \"tensorflow\"\n",
    "    ]), \n",
    "    name=\"v1-rnn\", # Name to identify the version in the model versions tab\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And That's it. You should now be able to see your Model, on your Catalog."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
