{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.056834,
     "end_time": "2020-11-28T23:01:34.209435",
     "exception": false,
     "start_time": "2020-11-28T23:01:34.152601",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Monitoring time series datasets on Verta\n",
    "\n",
    "Verta provides a extensible [model monitoring framework](https://docs.verta.ai/verta/monitoring) that allows the user to fully define and configure what data to monitor and how to monitor it.\n",
    "\n",
    "This notebook shows an example of how Verta model monitoring can be used with time series data and a Prophet model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "import itertools\n",
    "import os\n",
    "import time\n",
    "from datetime import date, datetime, timedelta, timezone\n",
    "\n",
    "import six\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "from fbprophet import Prophet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1 Verta import and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restart your notebook if prompted on Colab\n",
    "try:\n",
    "    import verta\n",
    "except ImportError:\n",
    "    !pip install verta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ['VERTA_EMAIL'] = \n",
    "# os.environ['VERTA_DEV_KEY'] = \n",
    "# os.environ['VERTA_HOST']\n",
    "\n",
    "from verta import Client\n",
    "client = Client(os.environ['VERTA_HOST'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Fetch data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget\n",
    "import pandas as pd\n",
    "\n",
    "def download_data_if_missing(filename):\n",
    "    url = \"https://verta-starter.s3.amazonaws.com/{}\".format(filename)\n",
    "    local_data_file = \"../data/{}\".format(filename)\n",
    "    if not os.path.isfile(local_data_file):\n",
    "        wget.download(url, out=local_data_file)\n",
    "\n",
    "filename = \"clean_manning_regressors.csv\"\n",
    "download_data_if_missing(filename)\n",
    "df = pd.read_csv(\"../data/{}\".format(filename))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define training set\n",
    "df_train = df[(df['ds'] <= '2011-12-31')]\n",
    "df_groundtruth = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define prophet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_train = Prophet()\n",
    "m_train.add_regressor('open')\n",
    "m_train.add_regressor('close')\n",
    "m_train.add_regressor('high')\n",
    "m_train.add_regressor('low')\n",
    "m_train.add_regressor('volume')\n",
    "m_train.add_regressor('adj_close')\n",
    "m_train.fit(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (for simulation) build full future forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_future = df[(df['ds'] > '2011-12-31') & (df['ds'] <= '2015-12-31')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_future.drop(columns=[\"y\"])\n",
    "full_forecast = m_train.predict(full_future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_between_start_end(start_str, end_str, df):\n",
    "    return df[(df['ds'] >= start_str) & (df['ds'] < end_str)]\n",
    "\n",
    "def get_forecast(start_str, end_str, forecast):\n",
    "    return df_between_start_end(start_str, end_str, forecast)\n",
    "\n",
    "def get_groundtruth(start, end, groundtruth):\n",
    "    return df_between_start_end(start_str, end_str, groundtruth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics\n",
    "def compute_mse(start, end, forecast, groundtruth):\n",
    "    # compute accuracy of forecast by using the true data\n",
    "    predicted = get_forecast(start, end, forecast)\n",
    "    actual = get_groundtruth(start, end, groundtruth)\n",
    "    return sklearn.metrics.mean_squared_error(predicted[\"yhat\"], actual[\"y\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define monitored entities\n",
    "\n",
    "In Verta Model Monitoring, a Monitored entity (ME) encapsulates the thing being monitored, e.g., a model, a pipeline, and acts as a context within which data summaries are produced and analyzed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "me = client.monitoring.get_or_create_monitored_entity(\"time-series-regression\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Define data summaries and summary samples\n",
    "\n",
    "For a specific ME, there are particular aspects of the data that we wish to monitor, e.g., for a model, we may want to monitor the inputs and outputs; for a dataset, we may want to monitor values in each column of the dataset.\n",
    "\n",
    "So the next step is to define the data _summaries_ we wish to capture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summaries and Summary Samples\n",
    "\n",
    "Users who are monitoring a deployed model, a data pipeline, or a model training process may be interested in many kinds of summary data including any number of summary statistics or data distribution summaries such as histograms. Within Verta's tools for data monitoring, a _summary_ defines a class of data which the user is interested in, for example a mean squared error or a histogram of data table column values. A _summary sample_ is an instance of that summary, which might be logged from a training epoch or a batch of inputs and outputs for a deployed model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from verta.monitoring.profiler import (\n",
    "    MissingValuesProfiler,\n",
    "    BinaryHistogramProfiler,\n",
    "    ContinuousHistogramProfiler,\n",
    ")\n",
    "\n",
    "continuous_profilers = [MissingValuesProfiler, ContinuousHistogramProfiler]\n",
    "from verta.data_types import (\n",
    "    DiscreteHistogram,\n",
    "    FloatHistogram,\n",
    "    NumericValue,\n",
    ")\n",
    "\n",
    "continuous_columns = [\"open\", \"close\", \"high\", \"low\", \"volume\", \"adj_close\"]\n",
    "\n",
    "def profile(data, mse, labels, start_time, end_time, monitored_entity):        \n",
    "    for col in continuous_columns:\n",
    "        summary_name = col + \"-Histogram\"\n",
    "        summary = client.monitoring.summaries.get_or_create(summary_name, FloatHistogram, monitored_entity)\n",
    "        # TODO: add binning\n",
    "        summary_samples = ContinuousHistogramProfiler(columns=[col]).profile(data)\n",
    "\n",
    "        for _, histogram in summary_samples.items():  \n",
    "            summary.log_sample(histogram, labels, start_time, end_time)\n",
    "\n",
    "    for col in continuous_columns:\n",
    "        missing_summary_name = col + \"-Missing\"\n",
    "        missing_summary = client.monitoring.summaries.get_or_create(missing_summary_name, DiscreteHistogram, monitored_entity)                \n",
    "        summary_samples = MissingValuesProfiler(columns=[col]).profile(data)\n",
    "\n",
    "        for _, missing_counts in summary_samples.items():  \n",
    "            missing_summary.log_sample(missing_counts, labels, start_time, end_time)\n",
    "            \n",
    "    mse_summary = client.monitoring.summaries.get_or_create(\"mse_summary\", NumericValue, monitored_entity)\n",
    "    mse_summary.log_sample(NumericValue(mse), labels, start_time, end_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Define alerts\n",
    "\n",
    "In many ways, monitors and summaries are just a way to get to our objective; know when unexpected things happen in the system. So next, we define alerts to notify us when somethin unexpected happens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from verta.monitoring.notification_channel import SlackNotificationChannel\n",
    "from verta.monitoring.alert import ReferenceAlerter, FixedAlerter\n",
    "from verta.monitoring.comparison import GreaterThan\n",
    "from verta.monitoring.summaries.queries import SummaryQuery\n",
    "from verta.monitoring.summaries.queries import SummarySampleQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta, timezone\n",
    "\n",
    "today = datetime.now(timezone.utc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel = None\n",
    "\n",
    "# supply a Slack notification channel, if available\n",
    "# channel = monitoring.notification_channels.get_or_create(\n",
    "#     \"Demo Monitoring Alerts\",\n",
    "#     SlackNotificationChannel(webhook_url)\n",
    "# )\n",
    "\n",
    "def set_alerts(monitored_entity):\n",
    "    summaries = client.monitoring.summaries.find(SummaryQuery(\n",
    "            monitored_entities=[monitored_entity.id],\n",
    "        ))\n",
    "    for summary in summaries:\n",
    "        if summary.name == \"mse_summary\":\n",
    "            mse_alert = summary.alerts.create(\n",
    "                \"MSE\",\n",
    "                FixedAlerter(GreaterThan(2.0)),\n",
    "                # notification_channels=[channel], # uncomment if channel is supplied\n",
    "                labels={\"source\":\"time_series\"},\n",
    "            )\n",
    "            continue\n",
    "        threshold = 0.2\n",
    "        ref_sample = summary.find_samples(SummarySampleQuery(labels={\"source\":\"reference\"}))[0]\n",
    "        alerter = ReferenceAlerter(\n",
    "            GreaterThan(threshold),\n",
    "            ref_sample,\n",
    "        )\n",
    "        alert = summary.alerts.create(\n",
    "            summary.name + \"- ReferenceDeviation GT {}\".format(threshold),\n",
    "            alerter,\n",
    "            # notification_channels=[channel], # uncomment if channel is supplied\n",
    "            starting_from=today-timedelta(hours=30), # pick a suitable time from which the alerter should be enabled\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Incorporate profiling functions into your workflow\n",
    "A typical data monitoring workflow works as follows: \n",
    "1. Log reference summaries (e.g., for training data, at training time)\n",
    "2. Log live/new summaries (e.g., when a daily job is re-run or when a model makes predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Log reference summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile(df_train, 0.3, {\"source\" : \"reference\"}, today - timedelta(hours=30), today - timedelta(hours=30), me)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_alerts(me)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: as defined above, our alerts need a reference sample to work correctly, so alerts must be set after logging\n",
    "# reference summary samples\n",
    "set_alerts(me)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Log live/new summaries\n",
    "\n",
    "Suppose in this case that we have a new dataset and we want to make sure that the new data matches the reference one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# month by month: loop over months\n",
    "years = [2015]\n",
    "# years = [2012, 2013, 2014, 2015]\n",
    "\n",
    "for year in years:\n",
    "    for month in range(1, 13):\n",
    "        start = datetime(year, month, 1, tzinfo=timezone.utc)\n",
    "        end_year, end_month = (year, month + 1) if month < 12 else (year + 1, 1)\n",
    "        end = datetime(end_year, end_month, 1, tzinfo=timezone.utc)\n",
    "\n",
    "        start_str = start.date().isoformat()\n",
    "        end_str = end.date().isoformat()\n",
    "        print(\"simulating summary for ({}, {})\".format(start_str, end_str))\n",
    "        mse = compute_mse(start_str, end_str, full_forecast, df_groundtruth)\n",
    "        \n",
    "        predicted = get_forecast(start_str, end_str, full_forecast)\n",
    "        actual = get_groundtruth(start_str, end_str, df_groundtruth)\n",
    "        profile(actual, mse, {\"source\":\"time_series\"}, start, end, me)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
