{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ItXfxkxvosLH"
   },
   "source": [
    "# Object Identification (TensorFlow Hub) - Local Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Eg62Pmz3o83v"
   },
   "source": [
    "This notebook identifies whether a given object is present in a set of images. If the object is found, it returns a dataframe with the file name, score and bounding boxes.\n",
    "\n",
    "We are using a dataset from [UCF](https://www.crcv.ucf.edu/data/GMCP_Geolocalization/#Dataset) that contains 62,058 high quality Google Street View images, and [TensorFlow Hub](https://www.tensorflow.org/hub), a library and platform for transfer learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook has been tested with the following package versions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Python 3.10.6\n",
    "!pip install matplotlib==3.6.2\n",
    "!pip install Pillow==9.3.0\n",
    "!pip install tensorflow==2.10.0\n",
    "!pip install tensorflow-hub==0.12.0\n",
    "!pip install urllib3==1.26.12\n",
    "!pip install verta==0.21.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import tempfile\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import time\n",
    "import urllib.request\n",
    "import warnings\n",
    "\n",
    "from PIL import Image, ImageOps\n",
    "from verta import Client\n",
    "from verta.environment import Python\n",
    "from verta.registry import VertaModelBase, verify_io\n",
    "from verta.utils import ModelAPI\n",
    "\n",
    "warnings.filterwarnings('ignore', category = FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Version: {tf.__version__}\")\n",
    "print(f\"Eager mode: {tf.executing_eagerly()}\")\n",
    "print(f\"Hub version: {hub.__version__}\")\n",
    "print(f'GPU is', 'AVAILABLE.' if tf.config.list_physical_devices('GPU') else 'NOT AVAILABLE.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up Verta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_NAME = 'Object-Detection'\n",
    "\n",
    "os.environ['VERTA_HOST'] = 'app.verta.ai'\n",
    "os.environ['VERTA_EMAIL'] = ''\n",
    "os.environ['VERTA_DEV_KEY'] = ''\n",
    "\n",
    "client = Client(os.environ['VERTA_HOST'], use_git = False)\n",
    "proj = client.set_project(PROJECT_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DetectObject(VertaModelBase):\n",
    "    def __init__(self, artifacts = None):\n",
    "        module_handle = 'https://tfhub.dev/google/openimages_v4/ssd/mobilenet_v2/1'\n",
    "        self.detector = hub.load(module_handle).signatures['default']\n",
    "    \n",
    "    def handle_img(self, img, width = 256, height = 256):\n",
    "        _, path = tempfile.mkstemp(suffix = '.jpg')\n",
    "        img = np.array(img, dtype = np.uint8)\n",
    "        img = Image.fromarray(img)\n",
    "        img = ImageOps.grayscale(img)\n",
    "        img.thumbnail((width, height), Image.Resampling.LANCZOS)\n",
    "        img.save(path, format = 'JPEG', quality = 90)\n",
    "        \n",
    "        print(f\"Image downloaded to {path}.\")\n",
    "        return path\n",
    "\n",
    "    def load_img(self, path):\n",
    "        img = tf.io.read_file(path)\n",
    "        img = tf.image.decode_jpeg(img, channels = 3)\n",
    "        \n",
    "        return img\n",
    "\n",
    "    def filter_results(self, file, response, entity = 'Car', min_score = .2):\n",
    "        unused_keys = ['detection_class_labels', 'detection_class_names']\n",
    "        response = {key: value.numpy().tolist() for key, value in response.items()}\n",
    "        response = dict([(key, val) for key, val in response.items() if key not in unused_keys])\n",
    "        response['detection_class_entities'] = [v.decode() for v in response['detection_class_entities']]\n",
    "\n",
    "        entities = response['detection_class_entities']\n",
    "        scores = response['detection_scores']\n",
    "        bboxes = response['detection_boxes']\n",
    "        result = {}\n",
    "\n",
    "        for i in range(len(entities)):\n",
    "            if entities[i] == entity and scores[i] >= min_score:\n",
    "                ymin, xmin, ymax, xmax = bboxes[i]\n",
    "                result = {\n",
    "                    'file': file,\n",
    "                    'has_car': 1,\n",
    "                    'score': scores[i],\n",
    "                    'bboxes': {'ymin': ymin, 'xmin': xmin, 'ymax': ymax, 'xmax': xmax}\n",
    "                }\n",
    "                break\n",
    "\n",
    "        if len(result) == 0:\n",
    "            result = {\n",
    "                'file': file,\n",
    "                'has_car': 0,\n",
    "                'score': 0,\n",
    "                'bboxes': {'ymin': 0, 'xmin': 0, 'ymax': 0, 'xmax': 0}\n",
    "            }\n",
    "        \n",
    "        print(f\"Found {result['has_car']} object(s).\")\n",
    "        return result\n",
    "\n",
    "    def run_detector(self, file, image_path):\n",
    "        img = self.load_img(image_path)\n",
    "        img = tf.image.convert_image_dtype(img, tf.float32)[tf.newaxis, ...]\n",
    "        \n",
    "        response = self.detector(img)\n",
    "        result = self.filter_results(file, response)\n",
    "        \n",
    "        return result\n",
    "\n",
    "    def detect_objects(self, file, img_arr):\n",
    "        start_time = time.time()\n",
    "        image_path = self.handle_img(img_arr, 640, 480)\n",
    "        result = self.run_detector(file, image_path)\n",
    "        end_time = time.time()\n",
    "\n",
    "        print(f\"Inference time: {end_time - start_time}.\")\n",
    "        return result\n",
    "\n",
    "    @verify_io\n",
    "    def predict(self, data):\n",
    "        result = self.detect_objects(data[0], data[1])\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "registered_model = client.get_or_create_registered_model(\n",
    "    name = 'object-detection', labels = ['object-detection']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = {\n",
    "    \"file_name\": \"\",\n",
    "    \"image_arr\": []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = {\n",
    "    \"file_name\": \"\",\n",
    "    \"has_car\": 0,\n",
    "    \"score\": 0,\n",
    "    \"ymin\": 0,\n",
    "    \"xmin\": 0,\n",
    "    \"ymax\": 0,\n",
    "    \"xmax\": 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_version = registered_model.create_standard_model(\n",
    "    model_cls = DetectObject,\n",
    "    environment = Python(requirements = ['tensorflow', 'tensorflow_hub', 'matplotlib']),\n",
    "    model_api = ModelAPI([input], [output]),\n",
    "    name = 'v1'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy Model to Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = client.get_or_create_endpoint('object-detection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint.update(model_version, wait = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployed_model = endpoint.get_deployed_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [\n",
    "    'http://www.cs.ucf.edu/~aroshan/index_files/Dataset_PitOrlManh/images/000001_0.jpg',\n",
    "    'http://www.cs.ucf.edu/~aroshan/index_files/Dataset_PitOrlManh/images/000001_1.jpg',\n",
    "    'http://www.cs.ucf.edu/~aroshan/index_files/Dataset_PitOrlManh/images/000001_2.jpg',\n",
    "    'http://www.cs.ucf.edu/~aroshan/index_files/Dataset_PitOrlManh/images/000001_3.jpg',\n",
    "    'http://www.cs.ucf.edu/~aroshan/index_files/Dataset_PitOrlManh/images/000001_4.jpg',\n",
    "    'http://www.cs.ucf.edu/~aroshan/index_files/Dataset_PitOrlManh/images/000001_5.jpg'\n",
    "]\n",
    "\n",
    "for url in urls:\n",
    "    urllib.request.urlretrieve(url, f\"images/{url.split('/')[-1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'images/'\n",
    "results = []\n",
    "\n",
    "for root, dirs, files in os.walk(folder):    \n",
    "    for file in sorted(files):\n",
    "        print(f\"Processing {file}...\")\n",
    "        img = Image.open(f\"{root}/{file}\")\n",
    "        img_arr = np.array(img).tolist()\n",
    "        result = deployed_model.predict([file, img_arr])\n",
    "        results.append(result)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Present Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(results[0].keys())[:-1]\n",
    "cols.extend(list(results[0]['bboxes'].keys()))\n",
    "data = []\n",
    "\n",
    "for item in results:\n",
    "    values = list(item.values())[0:3]\n",
    "    values.extend(list(item['bboxes'].values()))\n",
    "    data.append(values)\n",
    "    \n",
    "df_output = pd.DataFrame(data, columns = cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "basic-text-classification-with-tfhub.ipynb",
   "private_outputs": true,
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
