{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import configparser\n",
    "import multiprocessing as mp\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "import json\n",
    "\n",
    "from verta import Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_imgs(n_imgs):\n",
    "    path = 'images/'\n",
    "    files = [file for file in sorted(os.listdir(path))][:n_imgs]\n",
    "    data = []\n",
    "\n",
    "    for file in files:\n",
    "        with open(f\"{path}{file}\", 'rb') as img:\n",
    "            img_bytes = base64.b64encode(img.read())\n",
    "            img_str = img_bytes.decode('utf-8')\n",
    "            img_str = json.dumps(img_str)\n",
    "            img_str = np.array(img_str).tolist()\n",
    "        \n",
    "        data.append([file, img_str])\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_metrics(n_imgs, n_threads, start_time, end_time):\n",
    "    total_time = end_time - start_time\n",
    "    total_time = time.strftime('%Mm %Ss', time.gmtime(total_time))\n",
    "    \n",
    "    print(f'Images processed: {n_imgs}.')\n",
    "    print(f'Threads: {n_threads}.')\n",
    "    print(f'Total time: {total_time}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(results, n_imgs):\n",
    "    cols = list(results[0].keys())[:-1]\n",
    "    cols.extend(list(results[0]['bboxes'].keys()))\n",
    "    data = []\n",
    "\n",
    "    for item in results:\n",
    "        values = list(item.values())[0:3]\n",
    "        values.extend(list(item['bboxes'].values()))\n",
    "        data.append(values)\n",
    "\n",
    "    df = pd.DataFrame(data, columns=cols)\n",
    "    df.to_csv(f\"results/{n_imgs}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read('config.ini')\n",
    "\n",
    "    VERTA_HOST = config['APP']['VERTA_HOST']\n",
    "    ENDPOINT_NAME = config['APP']['ENDPOINT_NAME']\n",
    "\n",
    "    os.environ['VERTA_EMAIL'] = config['APP']['VERTA_EMAIL']\n",
    "    os.environ['VERTA_DEV_KEY'] = config['APP']['VERTA_DEV_KEY']\n",
    "\n",
    "    client = Client(VERTA_HOST, debug=True)\n",
    "    endpoint = client.get_or_create_endpoint(ENDPOINT_NAME)\n",
    "    model = endpoint.get_deployed_model()\n",
    "\n",
    "    n_threads = int(mp.cpu_count())\n",
    "    n_imgs = 5  \n",
    "    imgs = load_imgs(n_imgs)\n",
    "        \n",
    "    start_time = time.time()\n",
    "    pool = mp.Pool(n_threads)\n",
    "    map_results = pool.map_async(model.predict, imgs, chunksize=1)\n",
    "\n",
    "    while not map_results.ready():\n",
    "        print(f\"Images remaining: {map_results._number_left}\")\n",
    "        time.sleep(5)\n",
    "\n",
    "    results = map_results.get()\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    end_time = time.time()\n",
    "\n",
    "    show_metrics(n_imgs, n_threads, start_time, end_time)\n",
    "    save_results(results, n_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got VERTA_EMAIL from environment\n",
      "got VERTA_DEV_KEY from environment\n",
      "[DEBUG] using credentials: EmailCredentials(caio@verta.ai, 68b041eb-****-****-****-************)\n",
      "connection successfully established\n",
      "got existing Endpoint: object-detection-base64\n",
      "Images remaining: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-29 18:00:14.965533: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-29 18:00:14.966730: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-29 18:00:14.968050: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-29 18:00:14.971275: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-29 18:00:14.971347: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-29 18:00:15.839756: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-29 18:00:15.839756: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-29 18:00:15.839817: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-29 18:00:15.839817: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-29 18:00:15.839823: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2022-11-29 18:00:15.839823: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2022-11-29 18:00:15.843365: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-29 18:00:15.843432: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-29 18:00:15.843437: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2022-11-29 18:00:15.874241: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-29 18:00:15.874338: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-29 18:00:15.874348: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2022-11-29 18:00:15.886329: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-29 18:00:15.886430: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-29 18:00:15.886442: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images processed: 5.\n",
      "Threads: 16.\n",
      "Total time: 00m 05s.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('.env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2bb62b3221a3e8eb4d56ef3abf33b59c1166039d4d316f70559cb86bddd6b450"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
