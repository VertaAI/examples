{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Identification (TensorFlow Hub) - Images URLs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook identifies whether a given object is present in a set of images. If the object is found, it returns a dataframe with the file name, score and bounding boxes.\n",
    "We are using a dataset from [UCF](https://www.crcv.ucf.edu/data/GMCP_Geolocalization/#Dataset) that contains 62,058 high quality Google Street View images, and [TensorFlow Hub](https://www.tensorflow.org/hub), a library and platform for transfer learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/VertaAI/examples/blob/main/deployment/tfhub/object-detection/url/object-detection-url-deploy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook has been tested with Python 3.10.6 and the following package versions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install dill==0.3.6\n",
    "!pip install Pillow==9.3.0\n",
    "!pip install tensorflow==2.11.0\n",
    "!pip install tensorflow-hub==0.12.0\n",
    "!pip install verta==0.21.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import time\n",
    "import urllib.request\n",
    "\n",
    "from PIL import Image, ImageOps\n",
    "from verta import Client\n",
    "from verta.endpoint.autoscaling import Autoscaling\n",
    "from verta.endpoint.autoscaling.metrics import CpuUtilizationTarget, MemoryUtilizationTarget, RequestsPerWorkerTarget\n",
    "from verta.endpoint.resources import Resources\n",
    "from verta.endpoint.update import DirectUpdateStrategy\n",
    "from verta.environment import Python\n",
    "from verta.registry import VertaModelBase, verify_io\n",
    "from verta.utils import ModelAPI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DetectObject(VertaModelBase):\n",
    "    def __init__(self, artifacts=None):\n",
    "        module_handle = 'https://tfhub.dev/google/openimages_v4/ssd/mobilenet_v2/1'\n",
    "        self.detector = hub.load(module_handle).signatures['default']\n",
    "    \n",
    "    def handle_img(self, data, width=640, height=480):\n",
    "        _, path = tempfile.mkstemp(suffix='.jpg')\n",
    "        file_path = f\"{tempfile.gettempdir()}/tmp-{data[0].split('/')[-1]}\"\n",
    "        urllib.request.urlretrieve(data[1], file_path)\n",
    "        img = Image.open(file_path)\n",
    "        img = ImageOps.grayscale(img)\n",
    "        img.thumbnail((width, height), Image.Resampling.LANCZOS)\n",
    "        img.save(path, format='JPEG', quality=90)\n",
    "        \n",
    "        print(f\"Image downloaded to {path}.\")\n",
    "        return path\n",
    "\n",
    "    def load_img(self, path):\n",
    "        img = tf.io.read_file(path)\n",
    "        img = tf.image.decode_jpeg(img, channels=3)\n",
    "        \n",
    "        return img\n",
    "\n",
    "    def filter_results(self, file, response, entity='Car', min_score=.2):\n",
    "        unused_keys = ['detection_class_labels', 'detection_class_names']\n",
    "        response = {key: value.numpy().tolist() for key, value in response.items()}\n",
    "        response = {key: val for key, val in response.items() if key not in unused_keys}\n",
    "        response['detection_class_entities'] = [v.decode() for v in response['detection_class_entities']]\n",
    "\n",
    "        entities = response['detection_class_entities']\n",
    "        scores = response['detection_scores']\n",
    "        bboxes = response['detection_boxes']\n",
    "        result = {}\n",
    "\n",
    "        for i in range(len(entities)):\n",
    "            if entities[i] == entity and scores[i] >= min_score:\n",
    "                ymin, xmin, ymax, xmax = bboxes[i]\n",
    "                result = {\n",
    "                    'file': file,\n",
    "                    'has_car': True,\n",
    "                    'score': scores[i],\n",
    "                    'bboxes': {'ymin': ymin, 'xmin': xmin, 'ymax': ymax, 'xmax': xmax}\n",
    "                }\n",
    "                break\n",
    "\n",
    "        if len(result) == 0:\n",
    "            result = {\n",
    "                'file': file,\n",
    "                'has_car': False,\n",
    "                'score': 0,\n",
    "                'bboxes': {'ymin': 0, 'xmin': 0, 'ymax': 0, 'xmax': 0}\n",
    "            }\n",
    "        \n",
    "        print(f\"Found {result['has_car']} object(s).\")\n",
    "        return result\n",
    "\n",
    "    def run_detector(self, file, image_path):\n",
    "        img = self.load_img(image_path)\n",
    "        img = tf.image.convert_image_dtype(img, tf.float32)[tf.newaxis, ...]\n",
    "        \n",
    "        response = self.detector(img)\n",
    "        result = self.filter_results(file, response)\n",
    "        \n",
    "        return result\n",
    "\n",
    "    def detect_objects(self, data):\n",
    "        start_time = time.time()\n",
    "        image_path = self.handle_img(data)\n",
    "        result = self.run_detector(data[0], image_path)\n",
    "        end_time = time.time()\n",
    "\n",
    "        print(f\"Inference time: {end_time - start_time}.\")\n",
    "        return result\n",
    "\n",
    "    @verify_io\n",
    "    def predict(self, data):\n",
    "        result = self.detect_objects(data)\n",
    "\n",
    "        return result\n",
    "\n",
    "    def describe(self):\n",
    "        \"\"\"Return a description of the service.\"\"\"\n",
    "        return {\n",
    "            \"method\": \"predict\",\n",
    "            \"args\": \"http://s3.amazonaws.com/verta-starter/street-view-images/000001_0.jpg\",\n",
    "            \"returns\": \"file, has_car, score, ymin, xmin, ymax, xmax\",\n",
    "            \"description\": \"\"\"\n",
    "                Identify whether a given object is present in the URL image, with its score and bounding boxes.\n",
    "            \"\"\",\n",
    "            \"input_description\": \"\"\"\n",
    "                A list with image URLs.\n",
    "            \"\"\",\n",
    "            \"output_description\": \"\"\"\n",
    "                A CSV file with information about all the processed images.\n",
    "                The columns presents the file names, if the object was found (boolean), its score and bounding boxes.\n",
    "            \"\"\"\n",
    "        }\n",
    "    \n",
    "    def example(self):\n",
    "        \"\"\"Return example input json-serializable data.\"\"\"\n",
    "        return [\"000001_0.jpg\", \"http://s3.amazonaws.com/verta-starter/street-view-images/000001_0.jpg\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verta Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VERTA_HOST = 'app.verta.ai'\n",
    "PROJECT_NAME = 'Object Detection V1'\n",
    "MODEL_NAME = 'url'\n",
    "ENDPOINT_NAME = 'object-detection-url'\n",
    "\n",
    "os.environ['VERTA_EMAIL'] = ''\n",
    "os.environ['VERTA_DEV_KEY'] = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(VERTA_HOST)\n",
    "project = client.set_project(PROJECT_NAME)\n",
    "registered_model = client.get_or_create_registered_model(\n",
    "    name = PROJECT_NAME, \n",
    "    labels = ['object-detection']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = {\n",
    "    \"file_name\": \"\",\n",
    "    \"image_str\": \"\"\n",
    "}\n",
    "output = {\n",
    "    \"file_name\": \"\",\n",
    "    \"has_car\": False,\n",
    "    \"score\": 0,\n",
    "    \"ymin\": 0,\n",
    "    \"xmin\": 0,\n",
    "    \"ymax\": 0,\n",
    "    \"xmax\": 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = registered_model.create_standard_model(\n",
    "    model_cls = DetectObject,\n",
    "    environment = Python(requirements = ['tensorflow', 'tensorflow_hub', 'dill', 'Pillow']),\n",
    "    model_api = ModelAPI([input], [output]),\n",
    "    name = MODEL_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VM Auto Scaling and Resources Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoscaling = Autoscaling(min_replicas = 1, max_replicas = 20, min_scale = 0.1, max_scale = 10)\n",
    "autoscaling.add_metric(CpuUtilizationTarget(0.6))\n",
    "autoscaling.add_metric(MemoryUtilizationTarget(0.7))\n",
    "autoscaling.add_metric(RequestsPerWorkerTarget(1))\n",
    "resources = Resources(cpu = 2., memory = '12Gi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Endpoint Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = client.get_or_create_endpoint(ENDPOINT_NAME)\n",
    "status = endpoint.update(\n",
    "    model, \n",
    "    strategy = DirectUpdateStrategy(),\n",
    "    autoscaling = autoscaling,\n",
    "    resources = resources,\n",
    "    wait = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert status['status'] == \"active\"\n",
    "url = 'http://s3.amazonaws.com/verta-starter/street-view-images/000001_0.jpg'\n",
    "file = url.split('/')[-1]\n",
    "endpoint.get_deployed_model().predict([file, url])\n",
    "print(status)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "a88be0c350f3368d00cb8cbcc8a29525670c96bbb38149ff34103f663f5a90a2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
