{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Identification (TensorFlow Hub) - Base64 Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook identifies whether a given object is present in a set of images. If the object is found, it returns a dataframe with the file name, score and bounding boxes.\n",
    "We are using a dataset from [UCF](https://www.crcv.ucf.edu/data/GMCP_Geolocalization/#Dataset) that contains 62,058 high quality Google Street View images, and [TensorFlow Hub](https://www.tensorflow.org/hub), a library and platform for transfer learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/VertaAI/examples/blob/main/deployment/tfhub/object-detection/base64/object-detection-base64-deploy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook has been tested with **Python 3.8.15** and the following package versions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install dill==0.3.6\n",
    "!pip install Pillow==7.1.2\n",
    "!pip install tensorflow==2.11.0\n",
    "!pip install tensorflow-hub==0.12.0\n",
    "!pip install verta==0.21.1\n",
    "!pip install wget==3.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import io\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import tempfile\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import time\n",
    "import wget\n",
    "\n",
    "from PIL import Image, ImageOps\n",
    "from verta import Client\n",
    "from verta.endpoint.autoscaling import Autoscaling\n",
    "from verta.endpoint.autoscaling.metrics import CpuUtilizationTarget, MemoryUtilizationTarget, RequestsPerWorkerTarget\n",
    "from verta.endpoint.resources import Resources\n",
    "from verta.endpoint.update import DirectUpdateStrategy\n",
    "from verta.environment import Python\n",
    "from verta.registry import VertaModelBase, verify_io\n",
    "from verta.utils import ModelAPI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DetectObject(VertaModelBase):\n",
    "    def __init__(self, artifacts=None):\n",
    "        module_handle = 'https://tfhub.dev/google/openimages_v4/ssd/mobilenet_v2/1'\n",
    "        self.detector = hub.load(module_handle).signatures['default']\n",
    "    \n",
    "    def handle_img(self, img, width=640, height=480):\n",
    "        _, path = tempfile.mkstemp(suffix='.jpg')\n",
    "        img_str = json.loads(img)\n",
    "        img_bytes = img_str.encode('utf-8')\n",
    "        img_bytes = io.BytesIO(base64.b64decode(img_bytes))\n",
    "        img_arr = np.array(Image.open(img_bytes), dtype=np.uint8)\n",
    "        img = Image.fromarray(img_arr)\n",
    "        img = ImageOps.grayscale(img)\n",
    "        img.thumbnail((width, height), Image.LANCZOS)\n",
    "        img.save(path)\n",
    "        \n",
    "        print(f\"Image downloaded to {path}.\")\n",
    "        return path\n",
    "\n",
    "    def load_img(self, path):\n",
    "        img = tf.io.read_file(path)\n",
    "        img = tf.image.decode_jpeg(img, channels=3)\n",
    "        \n",
    "        return img\n",
    "\n",
    "    def filter_results(self, file, response, entity='Car', min_score=.2):\n",
    "        unused_keys = ['detection_class_labels', 'detection_class_names']\n",
    "        response = {key: value.numpy().tolist() for key, value in response.items()}\n",
    "        response = {key: val for key, val in response.items() if key not in unused_keys}\n",
    "        response['detection_class_entities'] = [v.decode() for v in response['detection_class_entities']]\n",
    "\n",
    "        entities = response['detection_class_entities']\n",
    "        scores = response['detection_scores']\n",
    "        bboxes = response['detection_boxes']\n",
    "        result = {}\n",
    "\n",
    "        for i in range(len(entities)):\n",
    "            if entities[i] == entity and scores[i] >= min_score:\n",
    "                ymin, xmin, ymax, xmax = bboxes[i]\n",
    "                result = {\n",
    "                    'file': file,\n",
    "                    'has_car': True,\n",
    "                    'score': scores[i],\n",
    "                    'bboxes': {'ymin': ymin, 'xmin': xmin, 'ymax': ymax, 'xmax': xmax}\n",
    "                }\n",
    "                break\n",
    "\n",
    "        if len(result) == 0:\n",
    "            result = {\n",
    "                'file': file,\n",
    "                'has_car': False,\n",
    "                'score': 0,\n",
    "                'bboxes': {'ymin': 0, 'xmin': 0, 'ymax': 0, 'xmax': 0}\n",
    "            }\n",
    "        \n",
    "        print(f\"Found {result['has_car']} object(s).\")\n",
    "        return result\n",
    "\n",
    "    def run_detector(self, file, image_path):\n",
    "        img = self.load_img(image_path)\n",
    "        img = tf.image.convert_image_dtype(img, tf.float32)[tf.newaxis, ...]\n",
    "        \n",
    "        response = self.detector(img)\n",
    "        result = self.filter_results(file, response)\n",
    "        \n",
    "        return result\n",
    "\n",
    "    def detect_objects(self, file, img_arr):\n",
    "        start_time = time.time()\n",
    "        image_path = self.handle_img(img_arr)\n",
    "        result = self.run_detector(file, image_path)\n",
    "        end_time = time.time()\n",
    "\n",
    "        print(f\"Inference time: {end_time - start_time}.\")\n",
    "        return result\n",
    "\n",
    "    @verify_io\n",
    "    def predict(self, data):\n",
    "        file, img_arr = data\n",
    "        result = self.detect_objects(file, img_arr)\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verta Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VERTA_HOST = 'app.verta.ai'\n",
    "PROJECT_NAME = 'Object Detection V1'\n",
    "MODEL_NAME = 'base64'\n",
    "ENDPOINT_NAME = 'object-detection-base64'\n",
    "\n",
    "os.environ['VERTA_EMAIL'] = ''\n",
    "os.environ['VERTA_DEV_KEY'] = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Registration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(VERTA_HOST)\n",
    "project = client.set_project(PROJECT_NAME)\n",
    "registered_model = client.get_or_create_registered_model(\n",
    "    name = PROJECT_NAME, \n",
    "    labels = ['object-detection']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = {\n",
    "    \"file_name\": \"\",\n",
    "    \"image_str\": \"\"\n",
    "}\n",
    "output = {\n",
    "    \"file_name\": \"\",\n",
    "    \"has_car\": False,\n",
    "    \"score\": 0,\n",
    "    \"ymin\": 0,\n",
    "    \"xmin\": 0,\n",
    "    \"ymax\": 0,\n",
    "    \"xmax\": 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = registered_model.create_standard_model(\n",
    "    model_cls = DetectObject,\n",
    "    environment = Python(requirements = ['tensorflow', 'tensorflow_hub', 'dill', 'Pillow', 'wget']),\n",
    "    model_api = ModelAPI([input], [output]),\n",
    "    name = MODEL_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VM Auto Scaling and Resources Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoscaling = Autoscaling(min_replicas = 1, max_replicas = 20, min_scale = 0.1, max_scale = 10)\n",
    "autoscaling.add_metric(CpuUtilizationTarget(0.6))\n",
    "autoscaling.add_metric(MemoryUtilizationTarget(0.7))\n",
    "autoscaling.add_metric(RequestsPerWorkerTarget(1))\n",
    "resources = Resources(cpu = 2., memory = '12Gi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Endpoint Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = client.get_or_create_endpoint(ENDPOINT_NAME)\n",
    "status = endpoint.update(\n",
    "    model, \n",
    "    strategy = DirectUpdateStrategy(),\n",
    "    autoscaling = autoscaling,\n",
    "    resources = resources,\n",
    "    wait = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert status['status'] == \"active\"\n",
    "url = 'http://s3.amazonaws.com/verta-starter/street-view-images/000001_0.jpg'\n",
    "file = os.path.basename(url)\n",
    "wget.download(url, file)\n",
    "\n",
    "with open(file, 'rb') as img:\n",
    "    img_bytes = base64.b64encode(img.read())\n",
    "    img_str = img_bytes.decode('utf-8')\n",
    "    img_str = json.dumps(img_str)\n",
    "\n",
    "endpoint.get_deployed_model().predict([file, img_str])\n",
    "print(status)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('.env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "8fcee05e428355ba9289075b405db6efadfd667fc0be61680b205b2b303cc40a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
