{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploying a Hugging Face (DistilBERT Sentiment Classification) model on Verta\n",
    "\n",
    "Within Verta, a \"Model\" can be any arbitrary function: a traditional ML model (e.g., sklearn, PyTorch, TF, etc); a function (e.g., squaring a number, making a DB function etc.); or a mixture of the above (e.g., pre-processing code, a DB call, and then a model application.) See more [here](https://docs.verta.ai/verta/registry/concepts).\n",
    "\n",
    "This notebook provides an example of how to deploy a Hugging Face model on Verta as a Verta Standard Model by extending [VertaModelBase](https://verta.readthedocs.io/en/master/_autogen/verta.registry.VertaModelBase.html?highlight=VertaModelBase#verta.registry.VertaModelBase).\n",
    "\n",
    "Updated for Verta version: 0.21.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook walks through creating a few DistilBERT and BERT sentiment classification models, logging them to the Verta platform, and deploying them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/VertaAI/examples/blob/main/deployment/huggingface/distilbert-sentiment-classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install verta\n",
    "!python -m pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    pipeline,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1 Verta import and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ['VERTA_EMAIL'] = \n",
    "# os.environ['VERTA_DEV_KEY'] = \n",
    "# os.environ['VERTA_HOST'] = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from verta import Client\n",
    "from verta.utils import ModelAPI\n",
    "\n",
    "client = Client(os.environ['VERTA_HOST'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Register model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Define model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A model has to exist before we can register and deploy a version, so we will instantiate one here in our notebook.\n",
    "\n",
    "This model class will be an extensible wrapper over a [pre-trained Hugging Face classifier](https://huggingface.co/transformers/index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from verta.registry import VertaModelBase, verify_io\n",
    "\n",
    "class _ModelBase(VertaModelBase):\n",
    "    MODEL = None\n",
    "\n",
    "    def __init__(self, artifacts=None):\n",
    "        self.model = pipeline(\n",
    "            task=\"sentiment-analysis\",\n",
    "            model=AutoModelForSequenceClassification.from_pretrained(self.MODEL),\n",
    "            tokenizer=AutoTokenizer.from_pretrained(self.MODEL),\n",
    "        )\n",
    "\n",
    "    @verify_io\n",
    "    def predict(self, texts):\n",
    "        return self.model(texts)\n",
    "\n",
    "    def example(self):\n",
    "        return [\n",
    "            \"I like you\",\n",
    "            \"I don't like this film\",\n",
    "        ]\n",
    "\n",
    "\n",
    "class DistilBERT(_ModelBase):\n",
    "    MODEL = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "\n",
    "    def predict(self, texts):\n",
    "        sentiments = super(DistilBERT, self).predict(texts)\n",
    "\n",
    "        return sentiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a sanity check, we can validate that our model is instantiable and can produce predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "distilbert = DistilBERT()\n",
    "\n",
    "texts = distilbert.example()\n",
    "prediction = distilbert.predict(texts)\n",
    "\n",
    "print(texts)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Register model for deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the model is in a good shape, we can register it into the Verta platform.\n",
    "\n",
    "We'll create a [registered model](https://verta.readthedocs.io/en/master/_autogen/verta.registry.entities.RegisteredModel.html) for our DistilBERT text classification models  \n",
    "and a [version](https://verta.readthedocs.io/en/master/_autogen/verta.registry.entities.RegisteredModelVersion.html) to associate this particular model with.\n",
    "\n",
    "All of these can be viewed in the Verta web app once they are created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "registered_model = client.get_or_create_registered_model(\n",
    "    \"DistilBERT\",\n",
    "    desc=\"Models trained for textual sentiment classification.\",\n",
    "    labels=[\"NLP\", \"Classification\", \"Neural Net\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from verta.environment import Python\n",
    "\n",
    "distilbert_model = registered_model.create_standard_model(\n",
    "    model_cls=DistilBERT,\n",
    "    model_api=ModelAPI(texts, prediction),\n",
    "    environment=Python([\n",
    "        \"dill\",  # used by torch internally for serialization\n",
    "        \"torch\",\n",
    "        \"transformers\",\n",
    "    ]),\n",
    "    # from https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english\n",
    "    attrs={\n",
    "        \"learning_rate\": 1e-5,\n",
    "        \"batch_size\": 32,\n",
    "        \"max_seq_length\": 128,\n",
    "        \"num_train_epochs\": 3,\n",
    "        \"accuracy\": .913,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Deploy model to endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from verta.endpoint.resources import Resources\n",
    "\n",
    "resources = Resources(memory=\"1Gi\")\n",
    "transformers_cache_env = {\"TRANSFORMERS_CACHE\": \"/tmp\"}\n",
    " \n",
    "sentiment_endpoint = client.get_or_create_endpoint(\"classify-sentiment\")\n",
    "sentiment_endpoint.update(  # can take ~10min for this model\n",
    "    distilbert_model,\n",
    "    resources=resources,\n",
    "    env_vars=transformers_cache_env,\n",
    "    wait=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployed_model = sentiment_endpoint.get_deployed_model()\n",
    "\n",
    "print(texts)\n",
    "print(deployed_model.predict(texts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Register additional models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One key aspect of the Verta platform is being able to organize your various models in a easy-to-navigate structure.  \n",
    "We can register additional BERT models—and be able to reference and deploy them as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Define models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "registered_model = client.get_or_create_registered_model(\n",
    "    \"BERT\",\n",
    "    labels=[\"NLP\", \"Classification\", \"Neural Net\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT(_ModelBase):\n",
    "    MODEL = \"textattack/bert-base-uncased-imdb\"\n",
    "\n",
    "    @verify_io\n",
    "    def predict(self, texts):\n",
    "        sentiments = super(BERT, self).predict(texts)\n",
    "\n",
    "        # fix labels\n",
    "        for sentiment in sentiments:\n",
    "            if sentiment['label'] == \"LABEL_0\":\n",
    "                sentiment['label'] = \"NEGATIVE\"\n",
    "            else:  # \"LABEL_1\"\n",
    "                sentiment['label'] = \"POSITIVE\"\n",
    "\n",
    "        return sentiments\n",
    "    \n",
    "bert_model = registered_model.create_standard_model(\n",
    "    model_cls=BERT,\n",
    "    model_api=ModelAPI(texts, prediction),\n",
    "    environment=Python([\"dill\", \"torch\", \"transformers\"]),\n",
    "    name=\"English BERT\",\n",
    "    labels=[\"BERT\", \"English\"],\n",
    "    # from https://huggingface.co/textattack/bert-base-uncased-imdb\n",
    "    attrs={\n",
    "        \"learning_rate\": 2e-5,\n",
    "        \"batch_size\": 16,\n",
    "        \"max_seq_length\": 128,\n",
    "        \"num_train_epochs\": 5,\n",
    "        \"accuracy\": .89088,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GermanBERT(_ModelBase):\n",
    "    MODEL = \"oliverguhr/german-sentiment-bert\"\n",
    "\n",
    "    @verify_io\n",
    "    def predict(self, texts):\n",
    "        sentiments = super(GermanBERT, self).predict(texts)\n",
    "        \n",
    "        # fix labels\n",
    "        for sentiment in sentiments:\n",
    "            sentiment['label'] = sentiment['label'].upper()\n",
    "\n",
    "        return sentiments\n",
    "\n",
    "german_model = registered_model.create_standard_model(\n",
    "    model_cls=GermanBERT,\n",
    "    model_api=ModelAPI(texts, prediction),\n",
    "    environment=Python([\"dill\", \"torch\", \"transformers\"]),\n",
    "    name=\"German\",\n",
    "    labels=[\"BERT\", \"German\"],\n",
    "    # from http://www.lrec-conf.org/proceedings/lrec2020/pdf/2020.lrec-1.202.pdf\n",
    "    attrs={\n",
    "        \"learning_rate\": 2e-5,\n",
    "        \"batch_size\": 32,\n",
    "        \"max_seq_length\": 256,\n",
    "        \"num_train_epochs\": 3,\n",
    "        \"f1\": .9639\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultilingualBERT(_ModelBase):\n",
    "    MODEL = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
    "\n",
    "    def __init__(self, artifacts=None):\n",
    "        super(MultilingualBERT, self).__init__()\n",
    "        self.model._postprocess_params.update({\"top_k\": None})  # this model has 5 categories, and we'll need to make it 2\n",
    "\n",
    "    @verify_io\n",
    "    def predict(self, texts):\n",
    "        texts_scores = super(MultilingualBERT, self).predict(texts)\n",
    "\n",
    "        # fix labels and scores\n",
    "        sentiments = []\n",
    "        for scores in texts_scores:\n",
    "            # aggregate negative and positive scores\n",
    "            negative_scores = filter(lambda score: score['label'] in {\"1 star\", \"2 stars\", \"3 stars\"}, scores)\n",
    "            positive_scores = filter(lambda score: score['label'] in {\"4 stars\", \"5 stars\"}, scores)\n",
    "            negative_score = sum(score['score'] for score in negative_scores)\n",
    "            positive_score = sum(score['score'] for score in positive_scores)\n",
    "\n",
    "            # select greater value as sentiment\n",
    "            if positive_score > negative_score:\n",
    "                label, score = \"POSITIVE\", positive_score\n",
    "            else:\n",
    "                label, score = \"NEGATIVE\", negative_score\n",
    "            sentiments.append({'label': label, 'score': score})\n",
    "\n",
    "        return sentiments\n",
    "\n",
    "multilingual_model = registered_model.create_standard_model(\n",
    "    model_cls=MultilingualBERT,\n",
    "    model_api=ModelAPI(texts, prediction),\n",
    "    environment=Python([\"dill\", \"torch\", \"transformers\"]),\n",
    "    name=\"Multilingual\",\n",
    "    labels=[\"BERT\", \"English\", \"German\"],\n",
    "    # from https://huggingface.co/nlptown/bert-base-multilingual-uncased-sentiment\n",
    "    attrs={  # example values; true hyperparameters not provided by model contributors\n",
    "        \"learning_rate\": 2e-5,\n",
    "        \"batch_size\": 16,\n",
    "        \"max_seq_length\": 128,\n",
    "        \"num_train_epochs\": 3,\n",
    "        \"accuracy\": .95,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Deploy models to endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_endpoint.update(\n",
    "    bert_model,\n",
    "    resources=resources,\n",
    "    env_vars=transformers_cache_env,\n",
    "    wait=True,\n",
    ")\n",
    "deployed_model = sentiment_endpoint.get_deployed_model()\n",
    "deployed_model.predict(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_endpoint.update(\n",
    "    german_model,\n",
    "    resources=resources,\n",
    "    env_vars=transformers_cache_env,\n",
    "    wait=True,\n",
    ")\n",
    "deployed_model = sentiment_endpoint.get_deployed_model()\n",
    "deployed_model.predict([\"Das ist gut\", \"Allergien machen keinen Spaß\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_endpoint.update(\n",
    "    multilingual_model,\n",
    "    resources=Resources(memory=\"2Gi\"),\n",
    "    env_vars=transformers_cache_env,\n",
    "    wait=True,\n",
    ")\n",
    "deployed_model = sentiment_endpoint.get_deployed_model()\n",
    "deployed_model.predict([\"Cette pâte est agréablement feuilletée\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
