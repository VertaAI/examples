{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tracking PyTorch models using Verta\n",
    "\n",
    "Verta's experiment management system enables data scientists to track rich information about their modeling experiments including data such as metrics, hyperparameters, confusion matrices, examples of input and output data, and many others.\n",
    "\n",
    "This notebook shows how to use Verta's experiment management system with models developed in PyTorch. See Verta [documentation](https://docs.verta.ai/verta/experiment-management) for full details on Verta's experiment management capabilities.\n",
    "\n",
    "Updated for Verta version: 0.18.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example features:\n",
    "\n",
    "- a **PyTorch** fully-connected neural network\n",
    "- a multi-epoch training loop\n",
    "- **verta**'s Python client logging training accuracy, as well as checkpoints of the model object every epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/VertaAI/examples/blob/main/experiment_management/torch/pytorch-checkpoints.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import datasets\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as func\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1 Verta import and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restart your notebook if prompted on Colab\n",
    "try:\n",
    "    import verta\n",
    "except ImportError:\n",
    "    !pip install verta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ['VERTA_EMAIL'] = \n",
    "# os.environ['VERTA_DEV_KEY'] = \n",
    "# os.environ['VERTA_HOST']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from verta import Client\n",
    "from verta.utils import ModelAPI\n",
    "\n",
    "client = Client(os.environ['VERTA_HOST'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = datasets.load_digits()\n",
    "\n",
    "X = data['data']\n",
    "y = data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.hstack((X, y.reshape(-1, 1))),\n",
    "                  columns=[\"pixel_{}\".format(i) for i in range(X.shape[-1])] + ['digit'])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather indices to split training data into training and validation sets\n",
    "shuffled_idxs = np.random.permutation(len(y))\n",
    "idxs_train = shuffled_idxs[int(len(shuffled_idxs)/10):]  # last 90%\n",
    "idxs_val = shuffled_idxs[:int(len(shuffled_idxs)/10)]  # first 10%\n",
    "\n",
    "X_train, y_train = (torch.tensor(X[idxs_train], dtype=torch.float),\n",
    "                    torch.tensor(y[idxs_train], dtype=torch.long))\n",
    "X_val, y_val = (torch.tensor(X[idxs_val], dtype=torch.float),\n",
    "                torch.tensor(y[idxs_val], dtype=torch.long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Dataset object to support batch training\n",
    "class TrainingDataset(data_utils.Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return (self.features[idx], self.labels[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enable batching of training data\n",
    "batch_size = 32\n",
    "\n",
    "dataset = TrainingDataset(X_train, y_train)\n",
    "dataloader = data_utils.DataLoader(dataset,\n",
    "                                   batch_size=batch_size,\n",
    "                                   shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 512\n",
    "dropout = 0.2\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, num_features=X.shape[1],\n",
    "                 hidden_size=hidden_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc      = nn.Linear(num_features, hidden_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.output  = nn.Linear(hidden_size, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.shape[0], -1)  # flatten non-batch dimensions\n",
    "        x = func.relu(self.fc(x))\n",
    "        x = self.dropout(x)\n",
    "        x = func.softmax(self.output(x), dim=-1)\n",
    "        return x\n",
    "\n",
    "model = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "proj = client.set_project(\"MNIST Multiclassification\")\n",
    "expt = client.set_experiment(\"FC-NN\")\n",
    "run = client.set_experiment_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.log_hyperparameter(\"batch_size\", batch_size)\n",
    "run.log_hyperparameter(\"hidden_size\", hidden_size)\n",
    "run.log_hyperparameter(\"dropout\", dropout)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "run.log_hyperparameter(\"loss_fn\", \"cross entropy\")\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "run.log_hyperparameter(\"optimizer\", \"adam\")\n",
    "\n",
    "num_epochs = 5\n",
    "run.log_hyperparameter(\"num_epochs\", num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_epoch in range(num_epochs):\n",
    "    for i_batch, (X_batch, y_batch) in enumerate(dataloader):\n",
    "        model.zero_grad()  # reset model gradients\n",
    "\n",
    "        output = model(X_batch)  # conduct forward pass\n",
    "\n",
    "        loss = criterion(output, y_batch)  # compare model output w/ ground truth\n",
    "        \n",
    "        print(\"\\repoch {}/{} | \".format(i_epoch+1, num_epochs), end='')\n",
    "        print(\"iteration {}/{} | \".format(i_batch+1, len(dataloader)), end='')\n",
    "        print(\"epoch loss avg: {}\".format(loss.item()), end='')\n",
    "\n",
    "        loss.backward()  # backpropogate loss to calculate gradients\n",
    "        optimizer.step()  # update model weights\n",
    "    \n",
    "    with torch.no_grad():  # no need to calculate gradients when assessing accuracy\n",
    "        print()\n",
    "        \n",
    "        pred_train = model(X_train).numpy().argmax(axis=1)\n",
    "        train_acc = (pred_train == y_train.numpy()).mean()\n",
    "        print(\"Training accuracy: {}\".format(train_acc))\n",
    "        run.log_observation(\"train_acc\", train_acc)\n",
    "        \n",
    "        pred_val = model(X_val).numpy().argmax(axis=1)\n",
    "        val_acc = (pred_val == y_val.numpy()).mean()\n",
    "        print(\"Validation accuracy: {}\".format(val_acc))\n",
    "        run.log_observation(\"val_acc\", val_acc)\n",
    "    \n",
    "    run.log_artifact(\"epoch_{}_checkpoint\".format(i_epoch), model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate final training accuracy\n",
    "with torch.no_grad():  # no need to calculate gradients when assessing accuracy\n",
    "    pred_train = model(X_train).numpy().argmax(axis=1)\n",
    "    train_acc = (pred_train == y_train.numpy()).mean()\n",
    "    print(\"Training accuracy: {}\".format(train_acc))\n",
    "    run.log_metric(\"train_acc\", train_acc)\n",
    "\n",
    "# log final model\n",
    "run.log_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# that's it! check your run below\n",
    "run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
